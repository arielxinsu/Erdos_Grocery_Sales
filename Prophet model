{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29781,"databundleVersionId":2887556,"sourceType":"competition"},{"sourceId":9910987,"sourceType":"datasetVersion","datasetId":6089648}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\ndf_train=pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/train.csv\")\ndf_test=pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/test.csv\")\nsample_subm=pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/sample_submission.csv\")  \n ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-15T17:30:25.011686Z","iopub.execute_input":"2024-11-15T17:30:25.012191Z","iopub.status.idle":"2024-11-15T17:30:30.297922Z","shell.execute_reply.started":"2024-11-15T17:30:25.012144Z","shell.execute_reply":"2024-11-15T17:30:30.296436Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"merged=pd.read_csv('/kaggle/input/merged-sales/merged_train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:30:30.300543Z","iopub.execute_input":"2024-11-15T17:30:30.301086Z","iopub.status.idle":"2024-11-15T17:30:47.985860Z","shell.execute_reply.started":"2024-11-15T17:30:30.301038Z","shell.execute_reply":"2024-11-15T17:30:47.984587Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2701438480.py:1: DtypeWarning: Columns (14,16,18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n  merged=pd.read_csv('/kaggle/input/merged-sales/merged_train.csv')\n","output_type":"stream"}]},{"cell_type":"code","source":"merged.columns","metadata":{"execution":{"iopub.status.busy":"2024-11-15T22:49:56.200233Z","iopub.execute_input":"2024-11-15T22:49:56.200722Z","iopub.status.idle":"2024-11-15T22:49:56.208471Z","shell.execute_reply.started":"2024-11-15T22:49:56.200677Z","shell.execute_reply":"2024-11-15T22:49:56.207304Z"},"trusted":true},"execution_count":112,"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"Index(['date', 'year', 'month', 'week_number', 'day', 'day_of_week',\n       'store_nbr', 'type', 'cluster', 'city', 'state', 'transactions', 'oil',\n       'hol_Nat', 'hol_Nat_name', 'hol_Reg', 'hol_Reg_name', 'hol_Loc',\n       'hol_loc_name', 'transferred', 'hol_type_Additional', 'hol_type_Bridge',\n       'hol_type_Event', 'hol_type_Holiday', 'hol_type_Transfer',\n       'hol_type_Work Day', 'family', 'onpromotion', 'sales'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":" merged[['date','sales']]","metadata":{"execution":{"iopub.status.busy":"2024-11-15T17:59:50.002095Z","iopub.execute_input":"2024-11-15T17:59:50.002510Z","iopub.status.idle":"2024-11-15T17:59:50.029126Z","shell.execute_reply.started":"2024-11-15T17:59:50.002471Z","shell.execute_reply":"2024-11-15T17:59:50.027834Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"              date    sales\n0       2013-01-01    0.000\n1       2013-01-01    0.000\n2       2013-01-01    2.000\n3       2013-01-01  810.000\n4       2013-01-01    0.000\n...            ...      ...\n2755099 2017-08-15   59.619\n2755100 2017-08-15   94.000\n2755101 2017-08-15  915.371\n2755102 2017-08-15    0.000\n2755103 2017-08-15    3.000\n\n[2755104 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2013-01-01</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2013-01-01</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2013-01-01</td>\n      <td>2.000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2013-01-01</td>\n      <td>810.000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2013-01-01</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2755099</th>\n      <td>2017-08-15</td>\n      <td>59.619</td>\n    </tr>\n    <tr>\n      <th>2755100</th>\n      <td>2017-08-15</td>\n      <td>94.000</td>\n    </tr>\n    <tr>\n      <th>2755101</th>\n      <td>2017-08-15</td>\n      <td>915.371</td>\n    </tr>\n    <tr>\n      <th>2755102</th>\n      <td>2017-08-15</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2755103</th>\n      <td>2017-08-15</td>\n      <td>3.000</td>\n    </tr>\n  </tbody>\n</table>\n<p>2755104 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Prophet","metadata":{}},{"cell_type":"code","source":"merged['date'] = pd.to_datetime(merged['date'], errors='coerce')  # Ensure 'date' is in datetime format","metadata":{"execution":{"iopub.status.busy":"2024-11-15T18:01:41.519702Z","iopub.execute_input":"2024-11-15T18:01:41.520776Z","iopub.status.idle":"2024-11-15T18:01:41.618384Z","shell.execute_reply.started":"2024-11-15T18:01:41.520719Z","shell.execute_reply":"2024-11-15T18:01:41.617197Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"train_new","metadata":{"execution":{"iopub.status.busy":"2024-11-15T18:02:47.156761Z","iopub.execute_input":"2024-11-15T18:02:47.157256Z","iopub.status.idle":"2024-11-15T18:02:47.175910Z","shell.execute_reply.started":"2024-11-15T18:02:47.157209Z","shell.execute_reply":"2024-11-15T18:02:47.174458Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"                ds  store_nbr  onpromotion        y  \\\n0       2013-01-01         25            0    0.000   \n1       2013-01-01         25            0    0.000   \n2       2013-01-01         25            0    2.000   \n3       2013-01-01         25            0  810.000   \n4       2013-01-01         25            0    0.000   \n...            ...        ...          ...      ...   \n2755099 2017-08-15         54            0   59.619   \n2755100 2017-08-15         54            0   94.000   \n2755101 2017-08-15         54           76  915.371   \n2755102 2017-08-15         54            0    0.000   \n2755103 2017-08-15         54            0    3.000   \n\n                             family  \n0                        AUTOMOTIVE  \n1                         BABY CARE  \n2                            BEAUTY  \n3                         BEVERAGES  \n4                             BOOKS  \n...                             ...  \n2755099                     POULTRY  \n2755100              PREPARED FOODS  \n2755101                     PRODUCE  \n2755102  SCHOOL AND OFFICE SUPPLIES  \n2755103                     SEAFOOD  \n\n[2755104 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ds</th>\n      <th>store_nbr</th>\n      <th>onpromotion</th>\n      <th>y</th>\n      <th>family</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2013-01-01</td>\n      <td>25</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>AUTOMOTIVE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2013-01-01</td>\n      <td>25</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>BABY CARE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2013-01-01</td>\n      <td>25</td>\n      <td>0</td>\n      <td>2.000</td>\n      <td>BEAUTY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2013-01-01</td>\n      <td>25</td>\n      <td>0</td>\n      <td>810.000</td>\n      <td>BEVERAGES</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2013-01-01</td>\n      <td>25</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>BOOKS</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2755099</th>\n      <td>2017-08-15</td>\n      <td>54</td>\n      <td>0</td>\n      <td>59.619</td>\n      <td>POULTRY</td>\n    </tr>\n    <tr>\n      <th>2755100</th>\n      <td>2017-08-15</td>\n      <td>54</td>\n      <td>0</td>\n      <td>94.000</td>\n      <td>PREPARED FOODS</td>\n    </tr>\n    <tr>\n      <th>2755101</th>\n      <td>2017-08-15</td>\n      <td>54</td>\n      <td>76</td>\n      <td>915.371</td>\n      <td>PRODUCE</td>\n    </tr>\n    <tr>\n      <th>2755102</th>\n      <td>2017-08-15</td>\n      <td>54</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>SCHOOL AND OFFICE SUPPLIES</td>\n    </tr>\n    <tr>\n      <th>2755103</th>\n      <td>2017-08-15</td>\n      <td>54</td>\n      <td>0</td>\n      <td>3.000</td>\n      <td>SEAFOOD</td>\n    </tr>\n  </tbody>\n</table>\n<p>2755104 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import logging\nimport cmdstanpy\nfrom itertools import product\nfrom tqdm import tqdm\nfrom prophet import Prophet\n\n# Suppress cmdstanpy logs\nlogging.getLogger(\"cmdstanpy\").setLevel(logging.WARNING)\n\n# Ensure 'date' is in datetime format\nmerged['date'] = pd.to_datetime(merged['date'], errors='coerce')\n\n# Rename and select columns\ntrain_new = merged.rename(columns={'date': 'ds', 'sales': 'y'})\ntrain_new = train_new[['ds', 'store_nbr', 'onpromotion', 'y', 'family']]\n\n# Initialize the dictionary to store the models\nmodels = {}\n\n# Get the unique categories and store numbers\nfamilies = train_new['family'].unique()\nstore_nbrs = train_new['store_nbr'].unique()\n\n# Initialize the progress bar\nprogress_bar = tqdm(product(families, store_nbrs), total=len(families) * len(store_nbrs), leave=False)\n\nfor fam, str_nbr in progress_bar:\n    # Update the progress bar with the current family and store\n    progress_bar.set_description(f\"Processing family {fam}, store {str_nbr}\")\n    \n    # Filter the dataframe for the specific category and store number\n    df_group = train_new[(train_new['family'] == fam) & (train_new['store_nbr'] == str_nbr)]\n    \n    # Drop rows where 'y' is NaN\n    df_group = df_group.dropna(subset=['y'])\n    \n    # Check if we have enough rows for Prophet\n    if df_group.shape[0] > 1:\n        # Initialize the Prophet model\n        model = Prophet()\n        model.add_regressor('onpromotion')\n        \n        # Fit the model to the category-store specific data\n        model.fit(df_group)\n        \n        # Store the fitted model in the dictionary with category and store number as key\n        models[(fam, str_nbr)] = model\n    else:\n        progress_bar.write(f\"Skipping {fam} and store {str_nbr} due to insufficient data.\")","metadata":{"execution":{"iopub.status.busy":"2024-11-15T22:55:11.093408Z","iopub.execute_input":"2024-11-15T22:55:11.093919Z","iopub.status.idle":"2024-11-15T22:57:28.205356Z","shell.execute_reply.started":"2024-11-15T22:55:11.093871Z","shell.execute_reply":"2024-11-15T22:57:28.203728Z"},"trusted":true},"execution_count":117,"outputs":[{"name":"stderr","text":"                                                                                         \r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[117], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m progress_bar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing family \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, store \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstr_nbr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Filter the dataframe for the specific category and store number\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m df_group \u001b[38;5;241m=\u001b[39m train_new[(\u001b[43mtrain_new\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfamily\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfam\u001b[49m) \u001b[38;5;241m&\u001b[39m (train_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_nbr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m str_nbr)]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Drop rows where 'y' is NaN\u001b[39;00m\n\u001b[1;32m     35\u001b[0m df_group \u001b[38;5;241m=\u001b[39m df_group\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:129\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"predictions = []  # Initialize the list to store predictions\ndf_test_new['date']=pd.to_datetime(df_test['date'], errors='coerce')\n\nfor fam, str_nbr in product(families, store_nbrs):\n    # Filter the test data for the specific family and store number\n    df_group_test = df_test_new[\n        (df_test_new['family'] == fam) & (df_test_new['store_nbr'] == str_nbr)\n    ].copy()\n    \n    # Check if test data is available\n    if df_group_test.empty:\n        print(f\"No test data found for family: {fam} and store number: {str_nbr}\")\n        continue\n\n    # Check if the corresponding model exists\n    if (fam, str_nbr) in models:\n        model = models[(fam, str_nbr)]  # Get the trained model for the family and store\n        \n        # Prepare the input data for prediction (must have 'ds' and 'onpromotion')\n        df_group_test = df_group_test[['id','ds', 'onpromotion', 'family', 'store_nbr']]\n        df_group_test['yhat']=0\n        # Make predictions for the specific combination\n        forecast = model.predict(df_group_test)\n        #print('Forecast:', forecast.iloc[1], 'fam:', fam, 'store_nbr:', str_nbr)\n        forecast = forecast.reset_index(drop=True)\n        df_group_test = df_group_test.reset_index(drop=True)\n        #print(forecast['yhat'])\n        # Add the predictions to the dataframe\n        df_group_test['yhat'] = forecast['yhat']\n        #print(df_group_test['yhat'])\n        # Store the predictions in the result DataFrame\n        predictions.append(df_group_test[['id','ds', 'yhat', 'family', 'store_nbr']])\n    else:\n        print(f\"No model found for family: {fam} and store number: {str_nbr}\")\n\n# Combine predictions into a single DataFrame\npredictions_df = pd.concat(predictions, ignore_index=True)\n\n# Display or save the predictions\nprint(predictions_df)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T22:24:20.990792Z","iopub.execute_input":"2024-11-15T22:24:20.991770Z","iopub.status.idle":"2024-11-15T22:26:20.534662Z","shell.execute_reply.started":"2024-11-15T22:24:20.991715Z","shell.execute_reply":"2024-11-15T22:26:20.533455Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"            id         ds       yhat      family  store_nbr\n0      3001449 2017-08-16   3.205540  AUTOMOTIVE         25\n1      3003231 2017-08-17   3.364007  AUTOMOTIVE         25\n2      3005013 2017-08-18   3.621863  AUTOMOTIVE         25\n3      3006795 2017-08-19   4.350825  AUTOMOTIVE         25\n4      3008577 2017-08-20   3.706243  AUTOMOTIVE         25\n...        ...        ...        ...         ...        ...\n28507  3022073 2017-08-27  14.698649     SEAFOOD         52\n28508  3023855 2017-08-28  11.946010     SEAFOOD         52\n28509  3025637 2017-08-29  14.369274     SEAFOOD         52\n28510  3027419 2017-08-30  10.465495     SEAFOOD         52\n28511  3029201 2017-08-31  11.660846     SEAFOOD         52\n\n[28512 rows x 5 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a mapping from 'id' to 'yhat'\nid_to_yhat_map = dict(zip(predictions_df['id'], predictions_df['yhat']))\n\n# Apply the mapping to populate the 'sales' column in sample_subm\nsample_subm['sales'] = sample_subm['id'].map(id_to_yhat_map)\nsample_subm[sal]","metadata":{"execution":{"iopub.status.busy":"2024-11-15T22:29:07.422232Z","iopub.execute_input":"2024-11-15T22:29:07.422746Z","iopub.status.idle":"2024-11-15T22:29:07.478183Z","shell.execute_reply.started":"2024-11-15T22:29:07.422697Z","shell.execute_reply":"2024-11-15T22:29:07.477015Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"            id        sales\n0      3000888     4.359173\n1      3000889     0.000000\n2      3000890     6.307344\n3      3000891  2233.817055\n4      3000892     0.479854\n...        ...          ...\n28507  3029395   346.235990\n28508  3029396   115.775556\n28509  3029397  1483.554356\n28510  3029398   132.053885\n28511  3029399    13.996081\n\n[28512 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3000888</td>\n      <td>4.359173</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3000889</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3000890</td>\n      <td>6.307344</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3000891</td>\n      <td>2233.817055</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3000892</td>\n      <td>0.479854</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28507</th>\n      <td>3029395</td>\n      <td>346.235990</td>\n    </tr>\n    <tr>\n      <th>28508</th>\n      <td>3029396</td>\n      <td>115.775556</td>\n    </tr>\n    <tr>\n      <th>28509</th>\n      <td>3029397</td>\n      <td>1483.554356</td>\n    </tr>\n    <tr>\n      <th>28510</th>\n      <td>3029398</td>\n      <td>132.053885</td>\n    </tr>\n    <tr>\n      <th>28511</th>\n      <td>3029399</td>\n      <td>13.996081</td>\n    </tr>\n  </tbody>\n</table>\n<p>28512 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# NO negative sales\nsample_subm.loc[sample_subm['sales']<0,'sales']=0","metadata":{"execution":{"iopub.status.busy":"2024-11-15T22:29:59.797004Z","iopub.execute_input":"2024-11-15T22:29:59.798108Z","iopub.status.idle":"2024-11-15T22:29:59.804995Z","shell.execute_reply.started":"2024-11-15T22:29:59.798060Z","shell.execute_reply":"2024-11-15T22:29:59.803675Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"sample_subm['sales'].describe()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-15T22:31:32.224669Z","iopub.execute_input":"2024-11-15T22:31:32.225129Z","iopub.status.idle":"2024-11-15T22:31:32.241592Z","shell.execute_reply.started":"2024-11-15T22:31:32.225084Z","shell.execute_reply":"2024-11-15T22:31:32.240048Z"},"trusted":true},"execution_count":91,"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"count    28512.000000\nmean       478.099152\nstd       1308.231614\nmin          0.000000\n25%          4.897236\n50%         30.533398\n75%        273.364037\nmax      16398.158015\nName: sales, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"sample_subm.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T22:34:37.486709Z","iopub.execute_input":"2024-11-15T22:34:37.487167Z","iopub.status.idle":"2024-11-15T22:34:37.587576Z","shell.execute_reply.started":"2024-11-15T22:34:37.487122Z","shell.execute_reply":"2024-11-15T22:34:37.586328Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}