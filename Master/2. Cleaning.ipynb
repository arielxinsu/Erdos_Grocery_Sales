{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "stores = pd.read_csv('../data/stores.csv')\n",
    "transactions = pd.read_csv('../data/transactions.csv')\n",
    "oil = pd.read_csv('../data/oil.csv')\n",
    "holidays = pd.read_csv('../data/holidays_events.csv')\n",
    "\n",
    "# Dictionary for all datasets\n",
    "datasets = {'train':train, 'test':test, 'stores':stores, 'transactions':transactions, 'oil':oil, 'holidays':holidays}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarizing dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert any dates in the datasets to pandas Timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in iter(datasets.values()):\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime( df['date'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Testing Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the `id` column from the training/testing set. The preliminary analysis proved this is just a redundant row indexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('id',axis=1)\n",
    "test = test.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oil Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change `dcoilwtico` to just `oil` for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil = oil.rename({'dcoilwtico': 'oil'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preliminary analysis shows 43 missing daily oil price values and missing weekend oil price values. \n",
    "\n",
    "We add the weekend days first as more null values, then interpolate \n",
    "\n",
    "Also, the oil price for the very first day (2013-01-01) is missing. We can manually add that here using the oil prices from 2012-12-31 and 2013-01-02 from (https://fred.stlouisfed.org/data/DCOILWTICO). We separately verified that is safe to do, since these oil prices match the ones in the oil dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually add oil price for the first day using average of 2012-12-31 and 2013-01-02 oil prices\n",
    "oil.iloc[0,1] = 92.485                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with all dates in desired range, including weekends\n",
    "dates = pd.DataFrame(pd.date_range(start='1/1/2013', end='8/31/2017',freq='D'), columns=['date'])\n",
    "# Merge with oil data set, so that weekend dates are added to oil with null values\n",
    "oil = dates.merge(oil,how='left', on='date')\n",
    "# Interpolate all missing values in oil (all but possibly one of the gaps are of size 1,2, or 3)\n",
    "oil['oil'] = oil['oil'].interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the `type` column so that it won't conflict with store type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = holidays.rename({'type':'hol_type'},axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the preliminary analysis, two transferred holidays need their description updated so that all tranfer holidays have consistent formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays.loc[304,'description'] = 'Traslado Fundacion de Cuenca'\n",
    "holidays.loc[329, 'description'] = 'Traslado Fundacion de Ibarra'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were also a couple mislabelled Additional Holidays, and one that should be deleted for redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays.loc[182,'type'] = 'Additional'\n",
    "holidays.loc[322,'type'] = 'Holiday'\n",
    "holidays = holidays.drop(264, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate the holiday `locale` variable into three columns (local, regional, national)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = pd.get_dummies(holidays, columns=['locale'],prefix='Hol')\n",
    "#We can adjust weights here or later\n",
    "holidays['Hol_Local']=holidays['Hol_Local']*1\n",
    "holidays['Hol_National']=holidays['Hol_National']*1\n",
    "holidays['Hol_Regional']=holidays['Hol_Regional']*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hol_type</th>\n",
       "      <th>city</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "      <th>Hol_Local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Loja</td>\n",
       "      <td>Fundacion de Loja</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date hol_type  city        description  transferred  Hol_Local\n",
       "202 2015-12-08  Holiday  Loja  Fundacion de Loja        False          1"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at local holidays\n",
    "hol_loc=holidays[holidays['Hol_Local']==1]\n",
    "hol_loc=hol_loc.rename(columns={'locale_name':'city'})\n",
    "hol_loc=hol_loc[['date', 'hol_type', 'city', 'description', 'transferred','Hol_Local']]\n",
    "hol_loc.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hol_type</th>\n",
       "      <th>state</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "      <th>Hol_Regional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2013-11-07</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Santa Elena</td>\n",
       "      <td>Provincializacion Santa Elena</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date hol_type        state                    description  \\\n",
       "77 2013-11-07  Holiday  Santa Elena  Provincializacion Santa Elena   \n",
       "\n",
       "    transferred  Hol_Regional  \n",
       "77        False             1  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at Regional holidays\n",
    "hol_reg=holidays[holidays['Hol_Regional']==1]\n",
    "hol_reg=hol_reg.rename(columns={'locale_name':'state'})\n",
    "hol_reg=hol_reg[['date', 'hol_type', 'state', 'description', 'transferred', 'Hol_Regional']]\n",
    "hol_reg.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hol_type</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "      <th>Hol_National</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2016-05-27</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>Traslado Batalla de Pichincha</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  hol_type                    description  transferred  \\\n",
       "256 2016-05-27  Transfer  Traslado Batalla de Pichincha        False   \n",
       "\n",
       "     Hol_National  \n",
       "256             1  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at National holidays\n",
    "hol_nat=holidays[holidays['Hol_National']==1]\n",
    "hol_nat=hol_nat[['date', 'hol_type', 'description', 'transferred', 'Hol_National']]\n",
    "hol_nat.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map of national holidays\n",
    "holiday_nat_map = dict(zip(hol_nat['date'], hol_nat['Hol_National']))\n",
    "holiday_nat_type_map = dict(zip(hol_nat['date'], hol_nat['hol_type']))\n",
    "holiday_nat_name_map = dict(zip(hol_nat['date'], hol_nat['description']))\n",
    "holiday_nat_transf_map = dict(zip(hol_nat['date'], hol_nat['transferred']))\n",
    "\n",
    "# Create a map of regional holidays\n",
    "holiday_reg_map = dict(zip(zip(hol_reg['date'], hol_reg['state'].str.strip()), hol_reg['Hol_Regional']))\n",
    "holiday_reg_type_map = dict(zip(zip(hol_reg['date'], hol_reg['state'].str.strip()), hol_reg['hol_type']))\n",
    "holiday_reg_name_map = dict(zip(zip(hol_reg['date'], hol_reg['state'].str.strip()), hol_reg['description']))\n",
    "holiday_reg_transf_map = dict(zip(hol_reg['date'], hol_reg['transferred']))\n",
    "\n",
    "# Create a map of local holidays\n",
    "holiday_loc_map = dict(zip(zip(hol_loc['date'], hol_loc['city'].str.strip()), hol_loc['Hol_Local']))\n",
    "holiday_loc_type_map = dict(zip(zip(hol_loc['date'], hol_loc['city'].str.strip()), hol_loc['hol_type']))\n",
    "holiday_loc_name_map = dict(zip(zip(hol_loc['date'], hol_loc['city'].str.strip()), hol_loc['description']))\n",
    "holiday_loc_transf_map = dict(zip(zip(hol_loc['date'], hol_loc['city'].str.strip()), hol_loc['transferred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first inner join the store and transaction data along the `store_nbr` column.\n",
    "\n",
    "This guarantees no duplicates or new null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge stores with transactions on date and store_nbr\n",
    "X = stores.merge(transactions, how='inner', on='store_nbr')\n",
    "X = X.sort_values(by=['date','store_nbr'],axis=0).reset_index(drop=True)\n",
    "X = X[['date','store_nbr','type','cluster','city','state','transactions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before merging more data, we break down the `date` column into year, month, w|eek, day, and day of week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.assign(**{'year': pd.Series( [X.date[i].year for i in X.index]), \n",
    "            'month': pd.Series( [X.date[i].month for i in X.index]), \n",
    "            'week_number': pd.Series( [X.date[i].week for i in X.index]), \n",
    "            'day':pd.Series( [X.date[i].day for i in X.index]), \n",
    "            'day_of_week': pd.Series( [X.date[i].dayofweek for i in X.index]) })\n",
    "X = X[['date','year', 'month', 'week_number', 'day', 'day_of_week','store_nbr','type','cluster','city', 'state', 'transactions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we  join oil prices along the `date` column.\n",
    "\n",
    "Since there is one oil price per date and we filled null values in oil, this won't give duplicates or new null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.merge(oil, how='left', on='date')\n",
    "X = X.sort_values(by=['date','store_nbr'],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we inner join our training data along both `date` and `store_nbr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.merge(train, how='left', on=['date','store_nbr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we join the holiday data using the mappings defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/wg74p6ds4615xyxvs58d4f_40000gn/T/ipykernel_97856/418294253.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[False False False ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X.loc[X['transferred'].isna(), 'transferred'] = X.loc[X['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
      "/var/folders/3d/wg74p6ds4615xyxvs58d4f_40000gn/T/ipykernel_97856/418294253.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Holiday' 'Holiday' 'Holiday' ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X.loc[X['hol_type'].isna(), 'hol_type'] = X['date'].map(holiday_nat_type_map)\n"
     ]
    }
   ],
   "source": [
    "# Add empty tranferred and holiday type columns\n",
    "X['transferred'] = np.nan\n",
    "X['hol_type'] = np.nan\n",
    "\n",
    "#Use mappings to fill in the values for national holidays\n",
    "X['hol_Nat'] = X['date'].map(holiday_nat_map)\n",
    "X.loc[X['transferred'].isna(), 'transferred'] = X.loc[X['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "X['hol_Nat_name'] = X['date'].map(holiday_nat_name_map)\n",
    "X.loc[X['hol_type'].isna(), 'hol_type'] = X['date'].map(holiday_nat_type_map)\n",
    "\n",
    "# Assign regional holidays based on mapping \n",
    "X['hol_Reg'] = X.apply(lambda row: holiday_reg_map.get((row['date'], row['state'])), axis=1)\n",
    "X.loc[X['transferred'].isna(), 'transferred'] = X.loc[X['transferred'].isna(), 'date'].map(holiday_reg_transf_map)\n",
    "X['hol_Reg_name'] = X.apply(lambda row: holiday_reg_name_map.get((row['date'], row['state'])), axis=1)\n",
    "X.loc[X['hol_type'].isna(), 'hol_type'] = X.loc[X['hol_type'].isna()].apply(lambda row: holiday_reg_type_map.get((row['date'], row['state'])), axis=1)\n",
    "\n",
    "# Assign local holidays based on mapping \n",
    "X['hol_Loc'] = X.apply(lambda row: holiday_loc_map.get((row['date'], row['city'])), axis=1)\n",
    "X.loc[X['transferred'].isna(), 'transferred'] = X.loc[X['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "\n",
    "X['transferred'] = X.apply(\n",
    "    lambda row: holiday_loc_map.get((row['date'], row['city'])) if pd.isna(row['transferred']) else row['transferred'], axis=1\n",
    ")\n",
    "X.loc[X['hol_type'].isna(), 'hol_type']= X.loc[X['hol_type'].isna()].apply(lambda row: holiday_loc_type_map.get((row['date'], row['city'])), axis=1)\n",
    "X['hol_loc_name'] = X.apply(lambda row: holiday_loc_name_map.get((row['date'], row['city'])), axis=1)\n",
    "\n",
    "# Just fillna\n",
    "X[['hol_Nat','hol_Reg','hol_Loc']]=X[['hol_Nat','hol_Reg','hol_Loc']].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder columns and create boolean columns for each holiday type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating types of the holidays \n",
    "X = pd.get_dummies(X,columns=['hol_type'], prefix='hol_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorder columns\n",
    "X = X[['date', 'year', 'month', 'week_number', 'day', 'day_of_week',\n",
    "       'store_nbr', 'type', 'cluster', 'city', 'state', 'transactions', 'oil',\n",
    "       'hol_Nat', 'hol_Nat_name', 'hol_Reg', 'hol_Reg_name', 'hol_Loc','hol_loc_name', \n",
    "       'transferred','hol_type_Additional', 'hol_type_Bridge', 'hol_type_Event',\n",
    "       'hol_type_Holiday', 'hol_type_Transfer', 'hol_type_Work Day',\n",
    "       'family', 'onpromotion', 'sales']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging (Alternative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach to merging starts with the training set, and ensures no rows of the training data are lost. However, as a result of NaN values and missing dates among the other data sets, this might contain some NaN values.\n",
    "\n",
    "Start with DataFrames containing all dates in the desired time frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame with all the days\n",
    "train_dates = pd.DataFrame(pd.date_range(start='1/1/2013', end='8/15/2017',freq='D'), columns=['date'])\n",
    "test_dates = pd.DataFrame(pd.date_range(start='8/16/2017', end='8/31/2017',freq='D'), columns=['date'])\n",
    "\n",
    "# Breaking down dates into year, month, day, etc.\n",
    "train_dates = train_dates.assign(**{'year': pd.Series( [train_dates.date[i].year for i in train_dates.index]), \n",
    "            'month': pd.Series( [train_dates.date[i].month for i in train_dates.index]), \n",
    "            'week_number': pd.Series( [train_dates.date[i].week for i in train_dates.index]), \n",
    "            'day':pd.Series( [train_dates.date[i].day for i in train_dates.index]), \n",
    "            'day_of_week': pd.Series( [train_dates.date[i].dayofweek for i in train_dates.index]) })\n",
    "test_dates = test_dates.assign(**{'year': pd.Series( [test_dates.date[i].year for i in test_dates.index]), \n",
    "            'month': pd.Series( [test_dates.date[i].month for i in test_dates.index]), \n",
    "            'week_number': pd.Series( [test_dates.date[i].week for i in test_dates.index]), \n",
    "            'day':pd.Series( [test_dates.date[i].day for i in test_dates.index]), \n",
    "            'day_of_week': pd.Series( [test_dates.date[i].dayofweek for i in test_dates.index]) })\n",
    "\n",
    "# Reorder columns\n",
    "train_dates = train_dates[['date','year', 'month', 'week_number', 'day', 'day_of_week']]\n",
    "test_dates = test_dates[['date','year', 'month', 'week_number', 'day', 'day_of_week']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add oil price for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add oil price for each day\n",
    "X_alt = oil.merge(train_dates, how='inner', on='date')\n",
    "y_alt = oil.merge(test_dates, how='inner', on='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left join training set data (left) with date/oil (right) along the `date` column.\n",
    "\n",
    "This ensures all training data is kept, while the date DataFrame drops December 25 2013, 2014, 2015, 2016, which are missing from train.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_alt = train.merge(X_alt, how='left', on='date')           # 3,000,888 rows\n",
    "y_alt = test.merge(y_alt, how='left', on='date')            # 28,512 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left join merged data (left) with stores (right) along the `store_nbr` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_alt = X_alt.merge(stores, how='left', on='store_nbr')     # 3,000,888 rows\n",
    "y_alt = y_alt.merge(stores, how='left', on='store_nbr')     # 28,512 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left join merged date (left) with transactions along `date` then `store_nbr`.\n",
    "\n",
    "Transactions is additionally missing data for Jan 1 and Jan 3 of 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the testing set has no transaction data, so we can't add that here\n",
    "X_alt = X_alt.merge(transactions, how='left', on=['date','store_nbr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a copy of the X_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy\n",
    "X_new = X_alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we add the holiday data using the mappings we constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/wg74p6ds4615xyxvs58d4f_40000gn/T/ipykernel_97856/3630162675.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[False False False ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X_alt.loc[X_alt['transferred'].isna(), 'transferred'] = X_alt.loc[X_alt['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
      "/var/folders/3d/wg74p6ds4615xyxvs58d4f_40000gn/T/ipykernel_97856/3630162675.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Holiday' 'Holiday' 'Holiday' ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X_alt.loc[X_alt['hol_type'].isna(), 'hol_type'] = X_alt['date'].map(holiday_nat_type_map)\n"
     ]
    }
   ],
   "source": [
    "# Add empty transferred and holiday type columns\n",
    "X_alt['transferred'] = np.nan\n",
    "X_alt['hol_type'] = np.nan\n",
    "\n",
    "#Use mappings to fill in the values for national holidays\n",
    "X_alt['hol_Nat'] = X_alt['date'].map(holiday_nat_map)\n",
    "X_alt.loc[X_alt['transferred'].isna(), 'transferred'] = X_alt.loc[X_alt['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "X_alt['hol_Nat_name'] = X_alt['date'].map(holiday_nat_name_map)\n",
    "X_alt.loc[X_alt['hol_type'].isna(), 'hol_type'] = X_alt['date'].map(holiday_nat_type_map)\n",
    "\n",
    "# Assign regional holidays based on mapping \n",
    "X_alt['hol_Reg'] = X_alt.apply(lambda row: holiday_reg_map.get((row['date'], row['state'])), axis=1)\n",
    "X_alt.loc[X_alt['transferred'].isna(), 'transferred'] = X_alt.loc[X_alt['transferred'].isna(), 'date'].map(holiday_reg_transf_map)\n",
    "X_alt['hol_Reg_name'] = X_alt.apply(lambda row: holiday_reg_name_map.get((row['date'], row['state'])), axis=1)\n",
    "X_alt.loc[X_alt['hol_type'].isna(), 'hol_type'] = X_alt.loc[X_alt['hol_type'].isna()].apply(lambda row: holiday_reg_type_map.get((row['date'], row['state'])), axis=1)\n",
    "\n",
    "# Assign local holidays based on mapping \n",
    "X_alt['hol_Loc'] = X_alt.apply(lambda row: holiday_loc_map.get((row['date'], row['city'])), axis=1)\n",
    "X_alt.loc[X_alt['transferred'].isna(), 'transferred'] = X_alt.loc[X_alt['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "\n",
    "X_alt['transferred'] = X_alt.apply(\n",
    "    lambda row: holiday_loc_map.get((row['date'], row['city'])) if pd.isna(row['transferred']) else row['transferred'], axis=1\n",
    ")\n",
    "X_alt.loc[X_alt['hol_type'].isna(), 'hol_type']= X_alt.loc[X_alt['hol_type'].isna()].apply(lambda row: holiday_loc_type_map.get((row['date'], row['city'])), axis=1)\n",
    "X_alt['hol_loc_name'] = X_alt.apply(lambda row: holiday_loc_name_map.get((row['date'], row['city'])), axis=1)\n",
    "\n",
    "# Just fillna\n",
    "X_alt[['hol_Nat','hol_Reg','hol_Loc']]=X_alt[['hol_Nat','hol_Reg','hol_Loc']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating types of the holidays \n",
    "X_alt = pd.get_dummies(X_alt,columns=['hol_type'], prefix='hol_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "X_alt = X_alt[['date', 'year', 'month', 'week_number', 'day', 'day_of_week', \n",
    "       'store_nbr','type', 'cluster', 'city', 'state','transactions','oil',\n",
    "       'hol_Nat','hol_Nat_name',  'hol_Reg','hol_Reg_name','hol_Loc','hol_loc_name',\n",
    "       'transferred','hol_type_Additional','hol_type_Bridge', 'hol_type_Event',\n",
    "       'hol_type_Holiday', 'hol_type_Transfer', 'hol_type_Work Day',\n",
    "       'family', 'onpromotion', 'sales']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week_number</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>transferred</th>\n",
       "      <th>hol_type_Additional</th>\n",
       "      <th>hol_type_Bridge</th>\n",
       "      <th>hol_type_Event</th>\n",
       "      <th>hol_type_Holiday</th>\n",
       "      <th>hol_type_Transfer</th>\n",
       "      <th>hol_type_Work Day</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619064</th>\n",
       "      <td>2014-02-10</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>B</td>\n",
       "      <td>16</td>\n",
       "      <td>Quito</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>HOME APPLIANCES</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115179</th>\n",
       "      <td>2014-12-26</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>Machala</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>EGGS</td>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507812</th>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>A</td>\n",
       "      <td>11</td>\n",
       "      <td>Quito</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>EGGS</td>\n",
       "      <td>2</td>\n",
       "      <td>329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359739</th>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>Cuenca</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>2</td>\n",
       "      <td>1230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890971</th>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>Machala</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>0</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  year  month  week_number  day  day_of_week  store_nbr  \\\n",
       "619064  2014-02-10  2014      2            7   10            0         18   \n",
       "1115179 2014-12-26  2014     12           52   26            4         40   \n",
       "2507812 2017-03-29  2017      3           13   29            2         45   \n",
       "1359739 2015-05-28  2015      5           22   28            3         39   \n",
       "1890971 2016-04-05  2016      4           14    5            1         40   \n",
       "\n",
       "        type  cluster     city  ... transferred  hol_type_Additional  \\\n",
       "619064     B       16    Quito  ...        None                False   \n",
       "1115179    C        3  Machala  ...       False                 True   \n",
       "2507812    A       11    Quito  ...        None                False   \n",
       "1359739    B        6   Cuenca  ...        None                False   \n",
       "1890971    C        3  Machala  ...        None                False   \n",
       "\n",
       "         hol_type_Bridge  hol_type_Event hol_type_Holiday  hol_type_Transfer  \\\n",
       "619064             False           False            False              False   \n",
       "1115179            False           False            False              False   \n",
       "2507812            False           False            False              False   \n",
       "1359739            False           False            False              False   \n",
       "1890971            False           False            False              False   \n",
       "\n",
       "        hol_type_Work Day           family onpromotion   sales  \n",
       "619064              False  HOME APPLIANCES           0     0.0  \n",
       "1115179             False             EGGS           0   137.0  \n",
       "2507812             False             EGGS           2   329.0  \n",
       "1359739             False         CLEANING           2  1230.0  \n",
       "1890971             False     BREAD/BAKERY           0   340.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week_number</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>transferred</th>\n",
       "      <th>hol_type_Additional</th>\n",
       "      <th>hol_type_Bridge</th>\n",
       "      <th>hol_type_Event</th>\n",
       "      <th>hol_type_Holiday</th>\n",
       "      <th>hol_type_Transfer</th>\n",
       "      <th>hol_type_Work Day</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2300267</th>\n",
       "      <td>2016-07-17</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>A</td>\n",
       "      <td>14</td>\n",
       "      <td>Ambato</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427059</th>\n",
       "      <td>2015-03-14</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>0</td>\n",
       "      <td>1128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943849</th>\n",
       "      <td>2017-07-14</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>Quito</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>HOME CARE</td>\n",
       "      <td>11</td>\n",
       "      <td>343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69174</th>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CELEBRATION</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135862</th>\n",
       "      <td>2013-03-18</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  year  month  week_number  day  day_of_week  store_nbr  \\\n",
       "2300267 2016-07-17  2016      7           28   17            6         50   \n",
       "1427059 2015-03-14  2015      3           11   14            5          5   \n",
       "2943849 2017-07-14  2017      7           28   14            4          9   \n",
       "69174   2013-02-08  2013      2            6    8            4          5   \n",
       "135862  2013-03-18  2013      3           12   18            0         21   \n",
       "\n",
       "        type  cluster           city  ... transferred  hol_type_Additional  \\\n",
       "2300267    A       14         Ambato  ...        None                False   \n",
       "1427059    D        4  Santo Domingo  ...        None                False   \n",
       "2943849    B        6          Quito  ...        None                False   \n",
       "69174      D        4  Santo Domingo  ...        None                False   \n",
       "135862     B        6  Santo Domingo  ...        None                False   \n",
       "\n",
       "         hol_type_Bridge  hol_type_Event hol_type_Holiday  hol_type_Transfer  \\\n",
       "2300267            False           False            False              False   \n",
       "1427059            False           False            False              False   \n",
       "2943849            False           False            False              False   \n",
       "69174              False           False            False              False   \n",
       "135862             False           False            False              False   \n",
       "\n",
       "        hol_type_Work Day       family onpromotion   sales  \n",
       "2300267             False       BEAUTY           1    17.0  \n",
       "1427059             False     CLEANING           0  1128.0  \n",
       "2943849             False    HOME CARE          11   343.0  \n",
       "69174               False  CELEBRATION           0     0.0  \n",
       "135862              False    BABY CARE           0     0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_alt.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.to_csv(\"../data/merged_train.csv\", index = False)\n",
    "#X_alt.to_csv(\"../data/merged_train_alt.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245784\n"
     ]
    }
   ],
   "source": [
    "print(X_alt['transactions'].isnull().sum())\n",
    "    # X_alt has missing values in transactions, and in the three holiday name columns\n",
    "    # the holiday day columns correspond to days with no holidays at all\n",
    "    # note that:\n",
    "        # number of fewer rows in merged_train == 245, 784 == number of missing transaction values in merged_train_alt \n",
    "    # i.e. merged_train has fewer rows, but has all values by skipping days without transaction data\n",
    "    # while merged_train_alt has all the original rows (3,000,888) but retains the NaN transaction values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix the tranfer issue and event label\n",
    "Starting from X_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holidays.transferred.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIx the map first \n",
    "# First the national holidays: \n",
    "\n",
    "# Looking at National holidays\n",
    "hol_nat_new=holidays[ (holidays['Hol_National']==1) & (holidays['hol_type'] != 'Event')]\n",
    "\n",
    "hol_nat_new=hol_nat_new[['date', 'hol_type', 'description', 'transferred', 'Hol_National']]\n",
    "hol_nat_new.sample()\n",
    "\n",
    "# Create a map of national holidays\n",
    "holiday_nat_map_new = dict(zip(hol_nat_new['date'], hol_nat_new['Hol_National']))\n",
    "holiday_nat_type_map_new = dict(zip(hol_nat_new['date'], hol_nat_new['hol_type']))\n",
    "holiday_nat_name_map_new = dict(zip(hol_nat_new['date'], hol_nat_new['description']))\n",
    "holiday_nat_transf_map_new = dict(zip(hol_nat_new['date'], hol_nat_new['transferred']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then create the df for events\n",
    "\n",
    "hol_event_new = holidays[ (holidays['Hol_National']==1) & (holidays['hol_type'] == 'Event')]\n",
    "hol_event_new = hol_event_new[['date', 'hol_type', 'description', 'transferred', 'Hol_National']]\n",
    "\n",
    "holiday_event_map_new = dict(zip(hol_event_new['date'], hol_event_new['Hol_National']))\n",
    "holiday_event_type_map_new = dict(zip(hol_event_new['date'], hol_event_new['hol_type']))\n",
    "holiday_event_name_map_new = dict(zip(hol_event_new['date'], hol_event_new['description']))\n",
    "holiday_event_transf_map_new = dict(zip(hol_event_new['date'], hol_event_new['transferred']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/wg74p6ds4615xyxvs58d4f_40000gn/T/ipykernel_97856/495347453.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[False False False ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X_new.loc[X_new['transferred'].isna(), 'transferred'] = X_new.loc[X_new['transferred'].isna(), 'date'].map(holiday_nat_transf_map_new)\n",
      "/var/folders/3d/wg74p6ds4615xyxvs58d4f_40000gn/T/ipykernel_97856/495347453.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Holiday' 'Holiday' 'Holiday' ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X_new.loc[X_new['hol_type'].isna(), 'hol_type'] = X_new['date'].map(holiday_nat_type_map_new)\n",
      "/var/folders/3d/wg74p6ds4615xyxvs58d4f_40000gn/T/ipykernel_97856/495347453.py:38: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_new['transferred'] = X_new['transferred'].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "# Add empty transferred and holiday type columns\n",
    "X_new['transferred'] = np.nan\n",
    "X_new['hol_type'] = np.nan\n",
    "\n",
    "#Use mappings to fill in the values for national holidays\n",
    "# Exclude national events. There're overlaping\n",
    "X_new['hol_Nat'] = X_new['date'].map(holiday_nat_map_new)\n",
    "X_new.loc[X_new['transferred'].isna(), 'transferred'] = X_new.loc[X_new['transferred'].isna(), 'date'].map(holiday_nat_transf_map_new)\n",
    "X_new['hol_Nat_name'] = X_new['date'].map(holiday_nat_name_map_new)\n",
    "X_new.loc[X_new['hol_type'].isna(), 'hol_type'] = X_new['date'].map(holiday_nat_type_map_new)\n",
    "\n",
    "# Add the event: \n",
    "X_new['event'] = X_new['date'].map(holiday_event_map_new)\n",
    "X_new.loc[X_new['transferred'].isna(), 'transferred'] = X_new.loc[X_new['transferred'].isna(), 'date'].map(holiday_event_transf_map_new)\n",
    "X_new['hol_event_name'] = X_new['date'].map(holiday_event_name_map_new)\n",
    "X_new.loc[X_new['hol_type'].isna(), 'hol_type'] = X_new['date'].map(holiday_event_type_map_new)\n",
    "\n",
    "# Assign regional holidays based on mapping \n",
    "X_new['hol_Reg'] = X_new.apply(lambda row: holiday_reg_map.get((row['date'], row['state'])), axis=1)\n",
    "X_new.loc[X_new['transferred'].isna(), 'transferred'] = X_new.loc[X_new['transferred'].isna(), 'date'].map(holiday_reg_transf_map)\n",
    "X_new['hol_Reg_name'] = X_new.apply(lambda row: holiday_reg_name_map.get((row['date'], row['state'])), axis=1)\n",
    "X_new.loc[X_new['hol_type'].isna(), 'hol_type'] = X_new.loc[X_new['hol_type'].isna()].apply(lambda row: holiday_reg_type_map.get((row['date'], row['state'])), axis=1)\n",
    "\n",
    "# Assign local holidays based on mapping \n",
    "X_new['hol_Loc'] = X_new.apply(lambda row: holiday_loc_map.get((row['date'], row['city'])), axis=1)\n",
    "X_new.loc[X_new['transferred'].isna(), 'transferred'] = X_new.loc[X_new['transferred'].isna(), 'date'].map(holiday_loc_transf_map)\n",
    "'''\n",
    "X_new['transferred'] = X_new.apply(\n",
    "    lambda row: holiday_loc_map.get((row['date'], row['city']) ) if pd.isna(row['transferred']) else row['transferred'], axis=1\n",
    ")\n",
    "'''\n",
    "X_new.loc[X_new['hol_type'].isna(), 'hol_type']= X_new.loc[X_new['hol_type'].isna()].apply(lambda row: holiday_loc_type_map.get((row['date'], row['city'])), axis=1)\n",
    "X_new['hol_loc_name'] = X_new.apply(lambda row: holiday_loc_name_map.get((row['date'], row['city'])), axis=1)\n",
    "\n",
    "# Just fillna\n",
    "X_new[['hol_Nat','hol_Reg','hol_Loc','event']]=X_new[['hol_Nat','hol_Reg','hol_Loc','event']].fillna(0)\n",
    "\n",
    "X_new['transferred'] = X_new['transferred'].fillna(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating types of the holidays \n",
    "X_new = pd.get_dummies(X_new,columns=['hol_type'], prefix='hol_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.transferred.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'year', 'month', 'week_number', 'day', 'day_of_week',\n",
       "       'store_nbr', 'type', 'cluster', 'city', 'state', 'transactions', 'oil',\n",
       "       'hol_Nat', 'hol_Nat_name', 'hol_Reg', 'hol_Reg_name', 'hol_Loc',\n",
       "       'hol_loc_name', 'transferred', 'hol_type_Additional', 'hol_type_Bridge',\n",
       "       'hol_type_Event', 'hol_type_Holiday', 'hol_type_Transfer',\n",
       "       'hol_type_Work Day', 'family', 'onpromotion', 'sales', 'event',\n",
       "       'hol_event_name', 'hol_type_Additional', 'hol_type_Bridge',\n",
       "       'hol_type_Event', 'hol_type_Holiday', 'hol_type_Transfer',\n",
       "       'hol_type_Work Day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "X_new = X_new[['date', 'year', 'month', 'week_number', 'day', 'day_of_week', \n",
    "       'store_nbr','type', 'cluster', 'city', 'state','transactions','oil',\n",
    "       'hol_Nat','hol_Nat_name',  'hol_Reg','hol_Reg_name','hol_Loc','hol_loc_name',\n",
    "       'event','hol_event_name','transferred','hol_type_Additional','hol_type_Bridge',\n",
    "       'hol_type_Event','hol_type_Holiday', 'hol_type_Transfer', 'hol_type_Work Day',\n",
    "       'family', 'onpromotion', 'sales']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the summary function to exam the data frame \n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current folder path\n",
    "current_folder = os.getcwd()\n",
    "# Add the parent directory to sys.path\n",
    "parent_folder = os.path.abspath(os.path.join(current_folder, \"..\"))\n",
    "sys.path.append(parent_folder)\n",
    "\n",
    "# Import the utility module\n",
    "import utility  # Now you can use utility.py as a module import utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (3000888, 38)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data type</th>\n",
       "      <th>#missing</th>\n",
       "      <th>%missing</th>\n",
       "      <th>#unique</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>first value</th>\n",
       "      <th>second value</th>\n",
       "      <th>third value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1684</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>2017-08-15 00:00:00</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_number</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>Pichincha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions</th>\n",
       "      <td>float64</td>\n",
       "      <td>245784</td>\n",
       "      <td>8.190376</td>\n",
       "      <td>4993</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8359.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oil</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1485</td>\n",
       "      <td>26.19</td>\n",
       "      <td>110.62</td>\n",
       "      <td>92.485</td>\n",
       "      <td>92.485</td>\n",
       "      <td>92.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_Nat</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_Nat_name</th>\n",
       "      <td>object</td>\n",
       "      <td>2840508</td>\n",
       "      <td>94.655582</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_Reg</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_Reg_name</th>\n",
       "      <td>object</td>\n",
       "      <td>2999865</td>\n",
       "      <td>99.965910</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_Loc</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_loc_name</th>\n",
       "      <td>object</td>\n",
       "      <td>2988645</td>\n",
       "      <td>99.592021</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_event_name</th>\n",
       "      <td>object</td>\n",
       "      <td>2902878</td>\n",
       "      <td>96.733967</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transferred</th>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_type_Additional</th>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_type_Additional</th>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_type_Bridge</th>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_type_Bridge</th>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_type_Event</th>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_type_Event</th>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_type_Holiday</th>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_type_Holiday</th>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_type_Transfer</th>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_type_Transfer</th>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_type_Work Day</th>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_type_Work Day</th>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>BEAUTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onpromotion</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>379610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124717.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hol_type</th>\n",
       "      <td>object</td>\n",
       "      <td>2733291</td>\n",
       "      <td>91.082740</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Holiday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utility.summary(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_new.to_csv(\"../data/merged_train_alt_new.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
