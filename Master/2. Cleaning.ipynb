{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "stores = pd.read_csv('../data/stores.csv')\n",
    "transactions = pd.read_csv('../data/transactions.csv')\n",
    "oil = pd.read_csv('../data/oil.csv')\n",
    "holidays = pd.read_csv('../data/holidays_events.csv')\n",
    "\n",
    "# Dictionary for all datasets\n",
    "datasets = {'train':train, 'test':test, 'stores':stores, 'transactions':transactions, 'oil':oil, 'holidays':holidays}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert any dates in the datasets to pandas Timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in iter(datasets.values()):\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime( df['date'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the `id` column from the training set. The preliminary analysis proved this is just a redundant row indexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preliminary analysis shows 43 missing daily oil price values and missing weekend oil price values. \n",
    "\n",
    "We add the weekend days first as more null values, then interpolate \n",
    "\n",
    "Also, the oil price for the very first day (2013-01-01) is missing. We can manually add that here using the oil prices from 2012-12-31 and 2013-01-02 from (https://fred.stlouisfed.org/data/DCOILWTICO). We separately verified that is safe to do, since these oil prices match the ones in the oil dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually add oil price for the first day using average of 2012-12-31 and 2013-01-02 oil prices\n",
    "oil.iloc[0,1] = 92.485                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with all dates in desired range, including weekends\n",
    "dates = pd.DataFrame(pd.date_range(start='1/1/2013', end='8/31/2017',freq='D'), columns=['date'])\n",
    "# Merge with oil data set, so that weekend dates are added to oil with null values\n",
    "oil = dates.merge(oil,how='left', on='date')\n",
    "# Interpolate all missing values in oil (all but possibly one of the gaps are of size 1,2, or 3)\n",
    "oil['dcoilwtico'] = oil['dcoilwtico'].interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first inner join the store and transaction data along the `store_nbr` column.\n",
    "\n",
    "This guarantees no duplicates or new null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge stores with transactions on date and store_nbr\n",
    "X = stores.merge(transactions, how='inner', on='store_nbr')\n",
    "X = X.sort_values(by=['date','store_nbr'],axis=0).reset_index(drop=True)\n",
    "X = X[['date','store_nbr','type','cluster','city','state','transactions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before merging more data, we break down the `date` column into year, month, week, day, and day of week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.assign(**{'year': pd.Series( [X.date[i].year for i in X.index]), \n",
    "            'month': pd.Series( [X.date[i].month for i in X.index]), \n",
    "            'week_number': pd.Series( [X.date[i].week for i in X.index]), \n",
    "            'day':pd.Series( [X.date[i].day for i in X.index]), \n",
    "            'day_of_week': pd.Series( [X.date[i].dayofweek for i in X.index]) })\n",
    "X = X[['date','year', 'month', 'week_number', 'day', 'day_of_week','store_nbr','type','cluster','city','state','transactions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we inner join oil prices along the `date` column.\n",
    "\n",
    "Since there is one oil price per date and we filled null values in oil, this won't give duplicates or new null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.merge(oil, how='left', on='date')\n",
    "X = X.sort_values(by=['date','store_nbr'],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we join the holiday data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be determined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we inner join our training data along both `date` and `store_nbr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.merge(train, how='inner', on=['date','store_nbr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"../data/combined.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
