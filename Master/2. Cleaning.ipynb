{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "stores = pd.read_csv('../data/stores.csv')\n",
    "transactions = pd.read_csv('../data/transactions.csv')\n",
    "oil = pd.read_csv('../data/oil.csv')\n",
    "holidays = pd.read_csv('../data/holidays_events.csv')\n",
    "\n",
    "# Dictionary for all datasets\n",
    "datasets = {'train':train, 'test':test, 'stores':stores, 'transactions':transactions, 'oil':oil, 'holidays':holidays}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarizing dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert any dates in the datasets to pandas Timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in iter(datasets.values()):\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime( df['date'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Testing Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the `id` column from the training/testing set. The preliminary analysis proved this is just a redundant row indexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('id',axis=1)\n",
    "test = test.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oil Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change `dcoilwtico` to just `oil` for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil = oil.rename({'dcoilwtico': 'oil'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preliminary analysis shows 43 missing daily oil price values and missing weekend oil price values. \n",
    "\n",
    "We add the weekend days first as more null values, then interpolate \n",
    "\n",
    "Also, the oil price for the very first day (2013-01-01) is missing. We can manually add that here using the oil prices from 2012-12-31 and 2013-01-02 from (https://fred.stlouisfed.org/data/DCOILWTICO). We separately verified that is safe to do, since these oil prices match the ones in the oil dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually add oil price for the first day using average of 2012-12-31 and 2013-01-02 oil prices\n",
    "oil.iloc[0,1] = 92.485                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with all dates in desired range, including weekends\n",
    "dates = pd.DataFrame(pd.date_range(start='1/1/2013', end='8/31/2017',freq='D'), columns=['date'])\n",
    "# Merge with oil data set, so that weekend dates are added to oil with null values\n",
    "oil = dates.merge(oil,how='left', on='date')\n",
    "# Interpolate all missing values in oil (all but possibly one of the gaps are of size 1,2, or 3)\n",
    "oil['oil'] = oil['oil'].interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the `type` column so that it won't conflict with store type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = holidays.rename({'type':'hol_type'},axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the preliminary analysis, two transferred holidays need their description updated so that all tranfer holidays have consistent formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays.loc[304,'description'] = 'Traslado Fundacion de Cuenca'\n",
    "holidays.loc[329, 'description'] = 'Traslado Fundacion de Ibarra'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were also a couple mislabelled Additional Holidays, and one that should be deleted for redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays.loc[182,'type'] = 'Additional'\n",
    "holidays.loc[322,'type'] = 'Holiday'\n",
    "holidays = holidays.drop(264, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate the holiday `locale` variable into three columns (local, regional, national)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = pd.get_dummies(holidays, columns=['locale'],prefix='Hol')\n",
    "#We can adjust weights here or later\n",
    "holidays['Hol_Local']=holidays['Hol_Local']*1\n",
    "holidays['Hol_National']=holidays['Hol_National']*1\n",
    "holidays['Hol_Regional']=holidays['Hol_Regional']*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hol_type</th>\n",
       "      <th>city</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "      <th>Hol_Local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2012-08-15</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Riobamba</td>\n",
       "      <td>Fundacion de Riobamba</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date hol_type      city            description  transferred  \\\n",
       "15 2012-08-15  Holiday  Riobamba  Fundacion de Riobamba        False   \n",
       "\n",
       "    Hol_Local  \n",
       "15          1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at local holidays\n",
    "hol_loc=holidays[holidays['Hol_Local']==1]\n",
    "hol_loc=hol_loc.rename(columns={'locale_name':'city'})\n",
    "hol_loc=hol_loc[['date', 'hol_type', 'city', 'description', 'transferred','Hol_Local']]\n",
    "hol_loc.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hol_type</th>\n",
       "      <th>state</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "      <th>Hol_Regional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2013-11-06</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>Provincializacion de Santo Domingo</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date hol_type                           state  \\\n",
       "76 2013-11-06  Holiday  Santo Domingo de los Tsachilas   \n",
       "\n",
       "                           description  transferred  Hol_Regional  \n",
       "76  Provincializacion de Santo Domingo        False             1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at Regional holidays\n",
    "hol_reg=holidays[holidays['Hol_Regional']==1]\n",
    "hol_reg=hol_reg.rename(columns={'locale_name':'state'})\n",
    "hol_reg=hol_reg[['date', 'hol_type', 'state', 'description', 'transferred', 'Hol_Regional']]\n",
    "hol_reg.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hol_type</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "      <th>Hol_National</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2012-12-23</td>\n",
       "      <td>Additional</td>\n",
       "      <td>Navidad-2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    hol_type description  transferred  Hol_National\n",
       "34 2012-12-23  Additional   Navidad-2        False             1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at National holidays\n",
    "hol_nat=holidays[holidays['Hol_National']==1]\n",
    "hol_nat=hol_nat[['date', 'hol_type', 'description', 'transferred', 'Hol_National']]\n",
    "hol_nat.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map of national holidays\n",
    "holiday_nat_map = dict(zip(hol_nat['date'], hol_nat['Hol_National']))\n",
    "holiday_nat_type_map = dict(zip(hol_nat['date'], hol_nat['hol_type']))\n",
    "holiday_nat_name_map = dict(zip(hol_nat['date'], hol_nat['description']))\n",
    "holiday_nat_transf_map = dict(zip(hol_nat['date'], hol_nat['transferred']))\n",
    "\n",
    "# Create a map of regional holidays\n",
    "holiday_reg_map = dict(zip(zip(hol_reg['date'], hol_reg['state'].str.strip()), hol_reg['Hol_Regional']))\n",
    "holiday_reg_type_map = dict(zip(zip(hol_reg['date'], hol_reg['state'].str.strip()), hol_reg['hol_type']))\n",
    "holiday_reg_name_map = dict(zip(zip(hol_reg['date'], hol_reg['state'].str.strip()), hol_reg['description']))\n",
    "holiday_reg_transf_map = dict(zip(hol_reg['date'], hol_reg['transferred']))\n",
    "\n",
    "# Create a map of local holidays\n",
    "holiday_loc_map = dict(zip(zip(hol_loc['date'], hol_loc['city'].str.strip()), hol_loc['Hol_Local']))\n",
    "holiday_loc_type_map = dict(zip(zip(hol_loc['date'], hol_loc['city'].str.strip()), hol_loc['hol_type']))\n",
    "holiday_loc_name_map = dict(zip(zip(hol_loc['date'], hol_loc['city'].str.strip()), hol_loc['description']))\n",
    "holiday_loc_transf_map = dict(zip(zip(hol_loc['date'], hol_loc['city'].str.strip()), hol_loc['transferred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first inner join the store and transaction data along the `store_nbr` column.\n",
    "\n",
    "This guarantees no duplicates or new null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge stores with transactions on date and store_nbr\n",
    "X = stores.merge(transactions, how='inner', on='store_nbr')\n",
    "X = X.sort_values(by=['date','store_nbr'],axis=0).reset_index(drop=True)\n",
    "X = X[['date','store_nbr','type','cluster','city','state','transactions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before merging more data, we break down the `date` column into year, month, w|eek, day, and day of week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.assign(**{'year': pd.Series( [X.date[i].year for i in X.index]), \n",
    "            'month': pd.Series( [X.date[i].month for i in X.index]), \n",
    "            'week_number': pd.Series( [X.date[i].week for i in X.index]), \n",
    "            'day':pd.Series( [X.date[i].day for i in X.index]), \n",
    "            'day_of_week': pd.Series( [X.date[i].dayofweek for i in X.index]) })\n",
    "X = X[['date','year', 'month', 'week_number', 'day', 'day_of_week','store_nbr','type','cluster','city', 'state', 'transactions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we  join oil prices along the `date` column.\n",
    "\n",
    "Since there is one oil price per date and we filled null values in oil, this won't give duplicates or new null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.merge(oil, how='left', on='date')\n",
    "X = X.sort_values(by=['date','store_nbr'],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we inner join our training data along both `date` and `store_nbr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.merge(train, how='left', on=['date','store_nbr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we join the holiday data using the mappings defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/wg74p6ds4615xyxvs58d4f_40000gn/T/ipykernel_54373/418294253.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[False False False ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X.loc[X['transferred'].isna(), 'transferred'] = X.loc[X['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
      "/var/folders/3d/wg74p6ds4615xyxvs58d4f_40000gn/T/ipykernel_54373/418294253.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Holiday' 'Holiday' 'Holiday' ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X.loc[X['hol_type'].isna(), 'hol_type'] = X['date'].map(holiday_nat_type_map)\n"
     ]
    }
   ],
   "source": [
    "# Add empty tranferred and holiday type columns\n",
    "X['transferred'] = np.nan\n",
    "X['hol_type'] = np.nan\n",
    "\n",
    "#Use mappings to fill in the values for national holidays\n",
    "X['hol_Nat'] = X['date'].map(holiday_nat_map)\n",
    "X.loc[X['transferred'].isna(), 'transferred'] = X.loc[X['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "X['hol_Nat_name'] = X['date'].map(holiday_nat_name_map)\n",
    "X.loc[X['hol_type'].isna(), 'hol_type'] = X['date'].map(holiday_nat_type_map)\n",
    "\n",
    "# Assign regional holidays based on mapping \n",
    "X['hol_Reg'] = X.apply(lambda row: holiday_reg_map.get((row['date'], row['state'])), axis=1)\n",
    "X.loc[X['transferred'].isna(), 'transferred'] = X.loc[X['transferred'].isna(), 'date'].map(holiday_reg_transf_map)\n",
    "X['hol_Reg_name'] = X.apply(lambda row: holiday_reg_name_map.get((row['date'], row['state'])), axis=1)\n",
    "X.loc[X['hol_type'].isna(), 'hol_type'] = X.loc[X['hol_type'].isna()].apply(lambda row: holiday_reg_type_map.get((row['date'], row['state'])), axis=1)\n",
    "\n",
    "# Assign local holidays based on mapping \n",
    "X['hol_Loc'] = X.apply(lambda row: holiday_loc_map.get((row['date'], row['city'])), axis=1)\n",
    "X.loc[X['transferred'].isna(), 'transferred'] = X.loc[X['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "\n",
    "X['transferred'] = X.apply(\n",
    "    lambda row: holiday_loc_map.get((row['date'], row['city'])) if pd.isna(row['transferred']) else row['transferred'], axis=1\n",
    ")\n",
    "X.loc[X['hol_type'].isna(), 'hol_type']= X.loc[X['hol_type'].isna()].apply(lambda row: holiday_loc_type_map.get((row['date'], row['city'])), axis=1)\n",
    "X['hol_loc_name'] = X.apply(lambda row: holiday_loc_name_map.get((row['date'], row['city'])), axis=1)\n",
    "\n",
    "# Just fillna\n",
    "X[['hol_Nat','hol_Reg','hol_Loc']]=X[['hol_Nat','hol_Reg','hol_Loc']].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder columns and create boolean columns for each holiday type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating types of the holidays \n",
    "X = pd.get_dummies(X,columns=['hol_type'], prefix='hol_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorder columns\n",
    "X = X[['date', 'year', 'month', 'week_number', 'day', 'day_of_week',\n",
    "       'store_nbr', 'type', 'cluster', 'city', 'state', 'transactions', 'oil',\n",
    "       'hol_Nat', 'hol_Nat_name', 'hol_Reg', 'hol_Reg_name', 'hol_Loc','hol_loc_name', \n",
    "       'transferred','hol_type_Additional', 'hol_type_Bridge', 'hol_type_Event',\n",
    "       'hol_type_Holiday', 'hol_type_Transfer', 'hol_type_Work Day',\n",
    "       'family', 'onpromotion', 'sales']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging (Alternative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach to merging starts with the training set, and ensures no rows of the training data are lost. However, as a result of NaN values and missing dates among the other data sets, this might contain some NaN values.\n",
    "\n",
    "Start with DataFrames containing all dates in the desired time frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame with all the days\n",
    "train_dates = pd.DataFrame(pd.date_range(start='1/1/2013', end='8/15/2017',freq='D'), columns=['date'])\n",
    "test_dates = pd.DataFrame(pd.date_range(start='8/16/2017', end='8/31/2017',freq='D'), columns=['date'])\n",
    "\n",
    "# Breaking down dates into year, month, day, etc.\n",
    "train_dates = train_dates.assign(**{'year': pd.Series( [train_dates.date[i].year for i in train_dates.index]), \n",
    "            'month': pd.Series( [train_dates.date[i].month for i in train_dates.index]), \n",
    "            'week_number': pd.Series( [train_dates.date[i].week for i in train_dates.index]), \n",
    "            'day':pd.Series( [train_dates.date[i].day for i in train_dates.index]), \n",
    "            'day_of_week': pd.Series( [train_dates.date[i].dayofweek for i in train_dates.index]) })\n",
    "test_dates = test_dates.assign(**{'year': pd.Series( [test_dates.date[i].year for i in test_dates.index]), \n",
    "            'month': pd.Series( [test_dates.date[i].month for i in test_dates.index]), \n",
    "            'week_number': pd.Series( [test_dates.date[i].week for i in test_dates.index]), \n",
    "            'day':pd.Series( [test_dates.date[i].day for i in test_dates.index]), \n",
    "            'day_of_week': pd.Series( [test_dates.date[i].dayofweek for i in test_dates.index]) })\n",
    "\n",
    "# Reorder columns\n",
    "train_dates = train_dates[['date','year', 'month', 'week_number', 'day', 'day_of_week']]\n",
    "test_dates = test_dates[['date','year', 'month', 'week_number', 'day', 'day_of_week']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add oil price for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add oil price for each day\n",
    "X_alt = oil.merge(train_dates, how='inner', on='date')\n",
    "y_alt = oil.merge(test_dates, how='inner', on='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left join training set data (left) with date/oil (right) along the `date` column.\n",
    "\n",
    "This ensures all training data is kept, while the date DataFrame drops December 25 2013, 2014, 2015, 2016, which are missing from train.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_alt = train.merge(X_alt, how='left', on='date')           # 3,000,888 rows\n",
    "y_alt = test.merge(y_alt, how='left', on='date')            # 28,512 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left join merged data (left) with stores (right) along the `store_nbr` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_alt = X_alt.merge(stores, how='left', on='store_nbr')     # 3,000,888 rows\n",
    "y_alt = y_alt.merge(stores, how='left', on='store_nbr')     # 28,512 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left join merged date (left) with transactions along `date` then `store_nbr`.\n",
    "\n",
    "Transactions is additionally missing data for Jan 1 and Jan 3 of 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the testing set has no transaction data, so we can't add that here\n",
    "X_alt = X_alt.merge(transactions, how='left', on=['date','store_nbr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we add the holiday data using the mappings we constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/wg74p6ds4615xyxvs58d4f_40000gn/T/ipykernel_54373/3630162675.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[False False False ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X_alt.loc[X_alt['transferred'].isna(), 'transferred'] = X_alt.loc[X_alt['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
      "/var/folders/3d/wg74p6ds4615xyxvs58d4f_40000gn/T/ipykernel_54373/3630162675.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Holiday' 'Holiday' 'Holiday' ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X_alt.loc[X_alt['hol_type'].isna(), 'hol_type'] = X_alt['date'].map(holiday_nat_type_map)\n"
     ]
    }
   ],
   "source": [
    "# Add empty transferred and holiday type columns\n",
    "X_alt['transferred'] = np.nan\n",
    "X_alt['hol_type'] = np.nan\n",
    "\n",
    "#Use mappings to fill in the values for national holidays\n",
    "X_alt['hol_Nat'] = X_alt['date'].map(holiday_nat_map)\n",
    "X_alt.loc[X_alt['transferred'].isna(), 'transferred'] = X_alt.loc[X_alt['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "X_alt['hol_Nat_name'] = X_alt['date'].map(holiday_nat_name_map)\n",
    "X_alt.loc[X_alt['hol_type'].isna(), 'hol_type'] = X_alt['date'].map(holiday_nat_type_map)\n",
    "\n",
    "# Assign regional holidays based on mapping \n",
    "X_alt['hol_Reg'] = X_alt.apply(lambda row: holiday_reg_map.get((row['date'], row['state'])), axis=1)\n",
    "X_alt.loc[X_alt['transferred'].isna(), 'transferred'] = X_alt.loc[X_alt['transferred'].isna(), 'date'].map(holiday_reg_transf_map)\n",
    "X_alt['hol_Reg_name'] = X_alt.apply(lambda row: holiday_reg_name_map.get((row['date'], row['state'])), axis=1)\n",
    "X_alt.loc[X_alt['hol_type'].isna(), 'hol_type'] = X_alt.loc[X_alt['hol_type'].isna()].apply(lambda row: holiday_reg_type_map.get((row['date'], row['state'])), axis=1)\n",
    "\n",
    "# Assign local holidays based on mapping \n",
    "X_alt['hol_Loc'] = X_alt.apply(lambda row: holiday_loc_map.get((row['date'], row['city'])), axis=1)\n",
    "X_alt.loc[X_alt['transferred'].isna(), 'transferred'] = X_alt.loc[X_alt['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "\n",
    "X_alt['transferred'] = X_alt.apply(\n",
    "    lambda row: holiday_loc_map.get((row['date'], row['city'])) if pd.isna(row['transferred']) else row['transferred'], axis=1\n",
    ")\n",
    "X_alt.loc[X_alt['hol_type'].isna(), 'hol_type']= X_alt.loc[X_alt['hol_type'].isna()].apply(lambda row: holiday_loc_type_map.get((row['date'], row['city'])), axis=1)\n",
    "X_alt['hol_loc_name'] = X_alt.apply(lambda row: holiday_loc_name_map.get((row['date'], row['city'])), axis=1)\n",
    "\n",
    "# Just fillna\n",
    "X_alt[['hol_Nat','hol_Reg','hol_Loc']]=X_alt[['hol_Nat','hol_Reg','hol_Loc']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating types of the holidays \n",
    "X_alt = pd.get_dummies(X_alt,columns=['hol_type'], prefix='hol_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "X_alt = X_alt[['date', 'year', 'month', 'week_number', 'day', 'day_of_week', \n",
    "       'store_nbr','type', 'cluster', 'city', 'state','transactions','oil',\n",
    "       'hol_Nat','hol_Nat_name',  'hol_Reg','hol_Reg_name','hol_Loc','hol_loc_name',\n",
    "       'transferred','hol_type_Additional','hol_type_Bridge', 'hol_type_Event',\n",
    "       'hol_type_Holiday', 'hol_type_Transfer', 'hol_type_Work Day',\n",
    "       'family', 'onpromotion', 'sales']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week_number</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>transferred</th>\n",
       "      <th>hol_type_Additional</th>\n",
       "      <th>hol_type_Bridge</th>\n",
       "      <th>hol_type_Event</th>\n",
       "      <th>hol_type_Holiday</th>\n",
       "      <th>hol_type_Transfer</th>\n",
       "      <th>hol_type_Work Day</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1112098</th>\n",
       "      <td>2014-12-23</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>E</td>\n",
       "      <td>10</td>\n",
       "      <td>Esmeraldas</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SCHOOL AND OFFICE SUPPLIES</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366840</th>\n",
       "      <td>2013-08-29</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>Machala</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>0</td>\n",
       "      <td>1604.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360841</th>\n",
       "      <td>2013-08-25</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "      <td>A</td>\n",
       "      <td>14</td>\n",
       "      <td>Quito</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>LADIESWEAR</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490704</th>\n",
       "      <td>2015-08-15</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>Playas</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>POULTRY</td>\n",
       "      <td>0</td>\n",
       "      <td>102.088005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171336</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>Quito</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  year  month  week_number  day  day_of_week  store_nbr  \\\n",
       "1112098 2014-12-23  2014     12           52   23            1         43   \n",
       "366840  2013-08-29  2013      8           35   29            3         41   \n",
       "360841  2013-08-25  2013      8           34   25            6         48   \n",
       "1490704 2015-08-15  2015      8           33   15            5         35   \n",
       "1171336 2015-02-01  2015      2            5    1            6          9   \n",
       "\n",
       "        type  cluster        city  ... transferred  hol_type_Additional  \\\n",
       "1112098    E       10  Esmeraldas  ...       False                 True   \n",
       "366840     D        4     Machala  ...        None                False   \n",
       "360841     A       14       Quito  ...        None                False   \n",
       "1490704    C        3      Playas  ...        None                False   \n",
       "1171336    B        6       Quito  ...        None                False   \n",
       "\n",
       "         hol_type_Bridge  hol_type_Event hol_type_Holiday  hol_type_Transfer  \\\n",
       "1112098            False           False            False              False   \n",
       "366840             False           False            False              False   \n",
       "360841             False           False            False              False   \n",
       "1490704            False           False            False              False   \n",
       "1171336            False           False            False              False   \n",
       "\n",
       "        hol_type_Work Day                      family onpromotion        sales  \n",
       "1112098             False  SCHOOL AND OFFICE SUPPLIES           0     0.000000  \n",
       "366840              False                   GROCERY I           0  1604.000000  \n",
       "360841              False                  LADIESWEAR           0     0.000000  \n",
       "1490704             False                     POULTRY           0   102.088005  \n",
       "1171336             False                   BABY CARE           0     0.000000  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week_number</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>transferred</th>\n",
       "      <th>hol_type_Additional</th>\n",
       "      <th>hol_type_Bridge</th>\n",
       "      <th>hol_type_Event</th>\n",
       "      <th>hol_type_Holiday</th>\n",
       "      <th>hol_type_Transfer</th>\n",
       "      <th>hol_type_Work Day</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021618</th>\n",
       "      <td>2016-02-12</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>Guayaquil</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>0</td>\n",
       "      <td>83.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505272</th>\n",
       "      <td>2013-10-11</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>E</td>\n",
       "      <td>10</td>\n",
       "      <td>Libertad</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>DELI</td>\n",
       "      <td>0</td>\n",
       "      <td>146.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009234</th>\n",
       "      <td>2016-02-05</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>Guayaquil</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>0</td>\n",
       "      <td>38.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850661</th>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>E</td>\n",
       "      <td>10</td>\n",
       "      <td>Esmeraldas</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>LIQUOR,WINE,BEER</td>\n",
       "      <td>5</td>\n",
       "      <td>47.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401614</th>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>E</td>\n",
       "      <td>10</td>\n",
       "      <td>Guayaquil</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  year  month  week_number  day  day_of_week  store_nbr  \\\n",
       "2021618 2016-02-12  2016      2            6   12            4         32   \n",
       "505272  2013-10-11  2013     10           41   11            4         36   \n",
       "2009234 2016-02-05  2016      2            5    5            4         34   \n",
       "2850661 2017-05-23  2017      5           21   23            1         43   \n",
       "401614  2013-08-14  2013      8           33   14            2         28   \n",
       "\n",
       "        type  cluster        city  ... transferred  hol_type_Additional  \\\n",
       "2021618    C        3   Guayaquil  ...        None                False   \n",
       "505272     E       10    Libertad  ...       False                False   \n",
       "2009234    B        6   Guayaquil  ...        None                False   \n",
       "2850661    E       10  Esmeraldas  ...        None                False   \n",
       "401614     E       10   Guayaquil  ...        None                False   \n",
       "\n",
       "         hol_type_Bridge  hol_type_Event hol_type_Holiday  hol_type_Transfer  \\\n",
       "2021618            False           False            False              False   \n",
       "505272             False           False            False               True   \n",
       "2009234            False           False            False              False   \n",
       "2850661            False           False            False              False   \n",
       "401614             False           False            False              False   \n",
       "\n",
       "        hol_type_Work Day            family onpromotion    sales  \n",
       "2021618             False      BREAD/BAKERY           0   83.000  \n",
       "505272              False              DELI           0  146.957  \n",
       "2009234             False    PREPARED FOODS           0   38.000  \n",
       "2850661             False  LIQUOR,WINE,BEER           5   47.000  \n",
       "401614              False             BOOKS           0    0.000  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_alt.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.to_csv(\"../data/merged_train.csv\", index = False)\n",
    "#X_alt.to_csv(\"../data/merged_train_alt.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245784\n"
     ]
    }
   ],
   "source": [
    "print(X_alt['transactions'].isnull().sum())\n",
    "    # X_alt has missing values in transactions, and in the three holiday name columns\n",
    "    # the holiday day columns correspond to days with no holidays at all\n",
    "    # note that:\n",
    "        # number of fewer rows in merged_train == 245, 784 == number of missing transaction values in merged_train_alt \n",
    "    # i.e. merged_train has fewer rows, but has all values by skipping days without transaction data\n",
    "    # while merged_train_alt has all the original rows (3,000,888) but retains the NaN transaction values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix the tranfer issue and event label\n",
    "Starting from X_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add empty transferred and holiday type columns\n",
    "X_new['transferred'] = np.nan\n",
    "X_new['hol_type'] = np.nan\n",
    "\n",
    "#Use mappings to fill in the values for national holidays\n",
    "# Exclude national events. There're overlaping\n",
    "X_new['hol_Nat'] = X_new['date'].map(holiday_nat_map)\n",
    "X_new.loc[X_new['transferred'].isna(), 'transferred'] = X_new.loc[X_new['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "X_new['hol_Nat_name'] = X_new['date'].map(holiday_nat_name_map)\n",
    "X_new.loc[X_new['hol_type'].isna(), 'hol_type'] = X_new['date'].map(holiday_nat_type_map)\n",
    "\n",
    "# Assign regional holidays based on mapping \n",
    "X_new['hol_Reg'] = X_new.apply(lambda row: holiday_reg_map.get((row['date'], row['state'])), axis=1)\n",
    "X_new.loc[X_new['transferred'].isna(), 'transferred'] = X_new.loc[X_new['transferred'].isna(), 'date'].map(holiday_reg_transf_map)\n",
    "X_new['hol_Reg_name'] = X_new.apply(lambda row: holiday_reg_name_map.get((row['date'], row['state'])), axis=1)\n",
    "X_new.loc[X_new['hol_type'].isna(), 'hol_type'] = X_new.loc[X_new['hol_type'].isna()].apply(lambda row: holiday_reg_type_map.get((row['date'], row['state'])), axis=1)\n",
    "\n",
    "# Assign local holidays based on mapping \n",
    "X_new['hol_Loc'] = X_new.apply(lambda row: holiday_loc_map.get((row['date'], row['city'])), axis=1)\n",
    "X_new.loc[X_new['transferred'].isna(), 'transferred'] = X_new.loc[X_new['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "\n",
    "X_new['transferred'] = X_new.apply(\n",
    "    lambda row: holiday_loc_map.get((row['date'], row['city'])) if pd.isna(row['transferred']) else row['transferred'], axis=1\n",
    ")\n",
    "X_new.loc[X_new['hol_type'].isna(), 'hol_type']= X_new.loc[X_new['hol_type'].isna()].apply(lambda row: holiday_loc_type_map.get((row['date'], row['city'])), axis=1)\n",
    "X_new['hol_loc_name'] = X_new.apply(lambda row: holiday_loc_name_map.get((row['date'], row['city'])), axis=1)\n",
    "\n",
    "# Just fillna\n",
    "X_new[['hol_Nat','hol_Reg','hol_Loc']]=X_new[['hol_Nat','hol_Reg','hol_Loc']].fillna(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
