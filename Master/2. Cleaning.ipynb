{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "stores = pd.read_csv('../data/stores.csv')\n",
    "transactions = pd.read_csv('../data/transactions.csv')\n",
    "oil = pd.read_csv('../data/oil.csv')\n",
    "holidays = pd.read_csv('../data/holidays_events.csv')\n",
    "\n",
    "# Dictionary for all datasets\n",
    "datasets = {'train':train, 'test':test, 'stores':stores, 'transactions':transactions, 'oil':oil, 'holidays':holidays}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarizing dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert any dates in the datasets to pandas Timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in iter(datasets.values()):\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime( df['date'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Testing Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the `id` column from the training/testing set. The preliminary analysis proved this is just a redundant row indexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('id',axis=1)\n",
    "test = test.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oil Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change `dcoilwtico` to just `oil` for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil = oil.rename({'dcoilwtico': 'oil'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preliminary analysis shows 43 missing daily oil price values and missing weekend oil price values. \n",
    "\n",
    "We add the weekend days first as more null values, then interpolate \n",
    "\n",
    "Also, the oil price for the very first day (2013-01-01) is missing. We can manually add that here using the oil prices from 2012-12-31 and 2013-01-02 from (https://fred.stlouisfed.org/data/DCOILWTICO). We separately verified that is safe to do, since these oil prices match the ones in the oil dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually add oil price for the first day using average of 2012-12-31 and 2013-01-02 oil prices\n",
    "oil.iloc[0,1] = 92.485                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with all dates in desired range, including weekends\n",
    "dates = pd.DataFrame(pd.date_range(start='1/1/2013', end='8/31/2017',freq='D'), columns=['date'])\n",
    "# Merge with oil data set, so that weekend dates are added to oil with null values\n",
    "oil = dates.merge(oil,how='left', on='date')\n",
    "# Interpolate all missing values in oil (all but possibly one of the gaps are of size 1,2, or 3)\n",
    "oil['oil'] = oil['oil'].interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the `type` column so that it won't conflict with store type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = holidays.rename({'type':'hol_type'},axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the preliminary analysis, two transferred holidays need their description updated so that all tranfer holidays have consistent formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays.loc[304,'description'] = 'Traslado Fundacion de Cuenca'\n",
    "holidays.loc[329, 'description'] = 'Traslado Fundacion de Ibarra'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were also a couple mislabelled Additional Holidays, and one that should be deleted for redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays.loc[182,'type'] = 'Additional'\n",
    "holidays.loc[322,'type'] = 'Holiday'\n",
    "holidays = holidays.drop(264, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate the holiday `locale` variable into three columns (local, regional, national)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = pd.get_dummies(holidays, columns=['locale'],prefix='Hol')\n",
    "#We can adjust weights here or later\n",
    "holidays['Hol_Local']=holidays['Hol_Local']*1\n",
    "holidays['Hol_National']=holidays['Hol_National']*1\n",
    "holidays['Hol_Regional']=holidays['Hol_Regional']*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hol_type</th>\n",
       "      <th>city</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "      <th>Hol_Local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2013-05-12</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Puyo</td>\n",
       "      <td>Cantonizacion del Puyo</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date hol_type  city             description  transferred  Hol_Local\n",
       "54 2013-05-12  Holiday  Puyo  Cantonizacion del Puyo        False          1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at local holidays\n",
    "hol_loc=holidays[holidays['Hol_Local']==1]\n",
    "hol_loc=hol_loc.rename(columns={'locale_name':'city'})\n",
    "hol_loc=hol_loc[['date', 'hol_type', 'city', 'description', 'transferred','Hol_Local']]\n",
    "hol_loc.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hol_type</th>\n",
       "      <th>state</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "      <th>Hol_Regional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Cotopaxi</td>\n",
       "      <td>Provincializacion de Cotopaxi</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date hol_type     state                    description  transferred  \\\n",
       "1 2012-04-01  Holiday  Cotopaxi  Provincializacion de Cotopaxi        False   \n",
       "\n",
       "   Hol_Regional  \n",
       "1             1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at Regional holidays\n",
    "hol_reg=holidays[holidays['Hol_Regional']==1]\n",
    "hol_reg=hol_reg.rename(columns={'locale_name':'state'})\n",
    "hol_reg=hol_reg[['date', 'hol_type', 'state', 'description', 'transferred', 'Hol_Regional']]\n",
    "hol_reg.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hol_type</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "      <th>Hol_National</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2016-05-16</td>\n",
       "      <td>Event</td>\n",
       "      <td>Terremoto Manabi+30</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date hol_type          description  transferred  Hol_National\n",
       "254 2016-05-16    Event  Terremoto Manabi+30        False             1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at National holidays\n",
    "hol_nat=holidays[holidays['Hol_National']==1]\n",
    "hol_nat=hol_nat[['date', 'hol_type', 'description', 'transferred', 'Hol_National']]\n",
    "hol_nat.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map of national holidays\n",
    "holiday_nat_map = dict(zip(hol_nat['date'], hol_nat['Hol_National']))\n",
    "holiday_nat_type_map = dict(zip(hol_nat['date'], hol_nat['hol_type']))\n",
    "holiday_nat_name_map = dict(zip(hol_nat['date'], hol_nat['description']))\n",
    "holiday_nat_transf_map = dict(zip(hol_nat['date'], hol_nat['transferred']))\n",
    "\n",
    "# Create a map of regional holidays\n",
    "holiday_reg_map = dict(zip(zip(hol_reg['date'], hol_reg['state'].str.strip()), hol_reg['Hol_Regional']))\n",
    "holiday_reg_type_map = dict(zip(zip(hol_reg['date'], hol_reg['state'].str.strip()), hol_reg['hol_type']))\n",
    "holiday_reg_name_map = dict(zip(zip(hol_reg['date'], hol_reg['state'].str.strip()), hol_reg['description']))\n",
    "holiday_reg_transf_map = dict(zip(hol_reg['date'], hol_reg['transferred']))\n",
    "\n",
    "# Create a map of local holidays\n",
    "holiday_loc_map = dict(zip(zip(hol_loc['date'], hol_loc['city'].str.strip()), hol_loc['Hol_Local']))\n",
    "holiday_loc_type_map = dict(zip(zip(hol_loc['date'], hol_loc['city'].str.strip()), hol_loc['hol_type']))\n",
    "holiday_loc_name_map = dict(zip(zip(hol_loc['date'], hol_loc['city'].str.strip()), hol_loc['description']))\n",
    "holiday_loc_transf_map = dict(zip(zip(hol_loc['date'], hol_loc['city'].str.strip()), hol_loc['transferred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first inner join the store and transaction data along the `store_nbr` column.\n",
    "\n",
    "This guarantees no duplicates or new null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge stores with transactions on date and store_nbr\n",
    "X = stores.merge(transactions, how='inner', on='store_nbr')\n",
    "X = X.sort_values(by=['date','store_nbr'],axis=0).reset_index(drop=True)\n",
    "X = X[['date','store_nbr','type','cluster','city','state','transactions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before merging more data, we break down the `date` column into year, month, w|eek, day, and day of week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.assign(**{'year': pd.Series( [X.date[i].year for i in X.index]), \n",
    "            'month': pd.Series( [X.date[i].month for i in X.index]), \n",
    "            'week_number': pd.Series( [X.date[i].week for i in X.index]), \n",
    "            'day':pd.Series( [X.date[i].day for i in X.index]), \n",
    "            'day_of_week': pd.Series( [X.date[i].dayofweek for i in X.index]) })\n",
    "X = X[['date','year', 'month', 'week_number', 'day', 'day_of_week','store_nbr','type','cluster','city', 'state', 'transactions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we  join oil prices along the `date` column.\n",
    "\n",
    "Since there is one oil price per date and we filled null values in oil, this won't give duplicates or new null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.merge(oil, how='left', on='date')\n",
    "X = X.sort_values(by=['date','store_nbr'],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we inner join our training data along both `date` and `store_nbr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.merge(train, how='left', on=['date','store_nbr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we join the holiday data using the mappings defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/840b8l353yv58xh3z45hs1tc0000gn/T/ipykernel_43727/418294253.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[False False False ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X.loc[X['transferred'].isna(), 'transferred'] = X.loc[X['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
      "/var/folders/26/840b8l353yv58xh3z45hs1tc0000gn/T/ipykernel_43727/418294253.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Holiday' 'Holiday' 'Holiday' ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X.loc[X['hol_type'].isna(), 'hol_type'] = X['date'].map(holiday_nat_type_map)\n"
     ]
    }
   ],
   "source": [
    "# Add empty tranferred and holiday type columns\n",
    "X['transferred'] = np.nan\n",
    "X['hol_type'] = np.nan\n",
    "\n",
    "#Use mappings to fill in the values for national holidays\n",
    "X['hol_Nat'] = X['date'].map(holiday_nat_map)\n",
    "X.loc[X['transferred'].isna(), 'transferred'] = X.loc[X['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "X['hol_Nat_name'] = X['date'].map(holiday_nat_name_map)\n",
    "X.loc[X['hol_type'].isna(), 'hol_type'] = X['date'].map(holiday_nat_type_map)\n",
    "\n",
    "# Assign regional holidays based on mapping \n",
    "X['hol_Reg'] = X.apply(lambda row: holiday_reg_map.get((row['date'], row['state'])), axis=1)\n",
    "X.loc[X['transferred'].isna(), 'transferred'] = X.loc[X['transferred'].isna(), 'date'].map(holiday_reg_transf_map)\n",
    "X['hol_Reg_name'] = X.apply(lambda row: holiday_reg_name_map.get((row['date'], row['state'])), axis=1)\n",
    "X.loc[X['hol_type'].isna(), 'hol_type'] = X.loc[X['hol_type'].isna()].apply(lambda row: holiday_reg_type_map.get((row['date'], row['state'])), axis=1)\n",
    "\n",
    "# Assign local holidays based on mapping \n",
    "X['hol_Loc'] = X.apply(lambda row: holiday_loc_map.get((row['date'], row['city'])), axis=1)\n",
    "X.loc[X['transferred'].isna(), 'transferred'] = X.loc[X['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "\n",
    "X['transferred'] = X.apply(\n",
    "    lambda row: holiday_loc_map.get((row['date'], row['city'])) if pd.isna(row['transferred']) else row['transferred'], axis=1\n",
    ")\n",
    "X.loc[X['hol_type'].isna(), 'hol_type']= X.loc[X['hol_type'].isna()].apply(lambda row: holiday_loc_type_map.get((row['date'], row['city'])), axis=1)\n",
    "X['hol_loc_name'] = X.apply(lambda row: holiday_loc_name_map.get((row['date'], row['city'])), axis=1)\n",
    "\n",
    "# Just fillna\n",
    "X[['hol_Nat','hol_Reg','hol_Loc']]=X[['hol_Nat','hol_Reg','hol_Loc']].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder columns and create boolean columns for each holiday type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating types of the holidays \n",
    "X = pd.get_dummies(X,columns=['hol_type'], prefix='hol_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorder columns\n",
    "X = X[['date', 'year', 'month', 'week_number', 'day', 'day_of_week',\n",
    "       'store_nbr', 'type', 'cluster', 'city', 'state', 'transactions', 'oil',\n",
    "       'hol_Nat', 'hol_Nat_name', 'hol_Reg', 'hol_Reg_name', 'hol_Loc','hol_loc_name', \n",
    "       'transferred','hol_type_Additional', 'hol_type_Bridge', 'hol_type_Event',\n",
    "       'hol_type_Holiday', 'hol_type_Transfer', 'hol_type_Work Day',\n",
    "       'family', 'onpromotion', 'sales']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging (Alternative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach to merging starts with the training set, and ensures no rows of the training data are lost. However, as a result of NaN values and missing dates among the other data sets, this might contain some NaN values.\n",
    "\n",
    "Start with DataFrames containing all dates in the desired time frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame with all the days\n",
    "train_dates = pd.DataFrame(pd.date_range(start='1/1/2013', end='8/15/2017',freq='D'), columns=['date'])\n",
    "test_dates = pd.DataFrame(pd.date_range(start='8/16/2017', end='8/31/2017',freq='D'), columns=['date'])\n",
    "\n",
    "# Breaking down dates into year, month, day, etc.\n",
    "train_dates = train_dates.assign(**{'year': pd.Series( [train_dates.date[i].year for i in train_dates.index]), \n",
    "            'month': pd.Series( [train_dates.date[i].month for i in train_dates.index]), \n",
    "            'week_number': pd.Series( [train_dates.date[i].week for i in train_dates.index]), \n",
    "            'day':pd.Series( [train_dates.date[i].day for i in train_dates.index]), \n",
    "            'day_of_week': pd.Series( [train_dates.date[i].dayofweek for i in train_dates.index]) })\n",
    "test_dates = test_dates.assign(**{'year': pd.Series( [test_dates.date[i].year for i in test_dates.index]), \n",
    "            'month': pd.Series( [test_dates.date[i].month for i in test_dates.index]), \n",
    "            'week_number': pd.Series( [test_dates.date[i].week for i in test_dates.index]), \n",
    "            'day':pd.Series( [test_dates.date[i].day for i in test_dates.index]), \n",
    "            'day_of_week': pd.Series( [test_dates.date[i].dayofweek for i in test_dates.index]) })\n",
    "\n",
    "# Reorder columns\n",
    "train_dates = train_dates[['date','year', 'month', 'week_number', 'day', 'day_of_week']]\n",
    "test_dates = test_dates[['date','year', 'month', 'week_number', 'day', 'day_of_week']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add oil price for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add oil price for each day\n",
    "X_alt = oil.merge(train_dates, how='inner', on='date')\n",
    "y_alt = oil.merge(test_dates, how='inner', on='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left join training set data (left) with date/oil (right) along the `date` column.\n",
    "\n",
    "This ensures all training data is kept, while the date DataFrame drops December 25 2013, 2014, 2015, 2016, which are missing from train.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_alt = train.merge(X_alt, how='left', on='date')           # 3,000,888 rows\n",
    "y_alt = test.merge(y_alt, how='left', on='date')            # 28,512 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left join merged data (left) with stores (right) along the `store_nbr` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_alt = X_alt.merge(stores, how='left', on='store_nbr')     # 3,000,888 rows\n",
    "y_alt = y_alt.merge(stores, how='left', on='store_nbr')     # 28,512 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left join merged date (left) with transactions along `date` then `store_nbr`.\n",
    "\n",
    "Transactions is additionally missing data for Jan 1 and Jan 3 of 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the testing set has no transaction data, so we can't add that here\n",
    "X_alt = X_alt.merge(transactions, how='left', on=['date','store_nbr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we add the holiday data using the mappings we constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/840b8l353yv58xh3z45hs1tc0000gn/T/ipykernel_59518/3630162675.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[False False False ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X_alt.loc[X_alt['transferred'].isna(), 'transferred'] = X_alt.loc[X_alt['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
      "/var/folders/26/840b8l353yv58xh3z45hs1tc0000gn/T/ipykernel_59518/3630162675.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Holiday' 'Holiday' 'Holiday' ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X_alt.loc[X_alt['hol_type'].isna(), 'hol_type'] = X_alt['date'].map(holiday_nat_type_map)\n"
     ]
    }
   ],
   "source": [
    "# Add empty transferred and holiday type columns\n",
    "X_alt['transferred'] = np.nan\n",
    "X_alt['hol_type'] = np.nan\n",
    "\n",
    "#Use mappings to fill in the values for national holidays\n",
    "X_alt['hol_Nat'] = X_alt['date'].map(holiday_nat_map)\n",
    "X_alt.loc[X_alt['transferred'].isna(), 'transferred'] = X_alt.loc[X_alt['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "X_alt['hol_Nat_name'] = X_alt['date'].map(holiday_nat_name_map)\n",
    "X_alt.loc[X_alt['hol_type'].isna(), 'hol_type'] = X_alt['date'].map(holiday_nat_type_map)\n",
    "\n",
    "# Assign regional holidays based on mapping \n",
    "X_alt['hol_Reg'] = X_alt.apply(lambda row: holiday_reg_map.get((row['date'], row['state'])), axis=1)\n",
    "X_alt.loc[X_alt['transferred'].isna(), 'transferred'] = X_alt.loc[X_alt['transferred'].isna(), 'date'].map(holiday_reg_transf_map)\n",
    "X_alt['hol_Reg_name'] = X_alt.apply(lambda row: holiday_reg_name_map.get((row['date'], row['state'])), axis=1)\n",
    "X_alt.loc[X_alt['hol_type'].isna(), 'hol_type'] = X_alt.loc[X_alt['hol_type'].isna()].apply(lambda row: holiday_reg_type_map.get((row['date'], row['state'])), axis=1)\n",
    "\n",
    "# Assign local holidays based on mapping \n",
    "X_alt['hol_Loc'] = X_alt.apply(lambda row: holiday_loc_map.get((row['date'], row['city'])), axis=1)\n",
    "X_alt.loc[X_alt['transferred'].isna(), 'transferred'] = X_alt.loc[X_alt['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "\n",
    "X_alt['transferred'] = X_alt.apply(\n",
    "    lambda row: holiday_loc_map.get((row['date'], row['city'])) if pd.isna(row['transferred']) else row['transferred'], axis=1\n",
    ")\n",
    "X_alt.loc[X_alt['hol_type'].isna(), 'hol_type']= X_alt.loc[X_alt['hol_type'].isna()].apply(lambda row: holiday_loc_type_map.get((row['date'], row['city'])), axis=1)\n",
    "X_alt['hol_loc_name'] = X_alt.apply(lambda row: holiday_loc_name_map.get((row['date'], row['city'])), axis=1)\n",
    "\n",
    "# Just fillna\n",
    "X_alt[['hol_Nat','hol_Reg','hol_Loc']]=X_alt[['hol_Nat','hol_Reg','hol_Loc']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating types of the holidays \n",
    "X_alt = pd.get_dummies(X_alt,columns=['hol_type'], prefix='hol_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "X_alt = X_alt[['date', 'year', 'month', 'week_number', 'day', 'day_of_week', \n",
    "       'store_nbr','type', 'cluster', 'city', 'state','transactions','oil',\n",
    "       'hol_Nat','hol_Nat_name',  'hol_Reg','hol_Reg_name','hol_Loc','hol_loc_name',\n",
    "       'transferred','hol_type_Additional','hol_type_Bridge', 'hol_type_Event',\n",
    "       'hol_type_Holiday', 'hol_type_Transfer', 'hol_type_Work Day',\n",
    "       'family', 'onpromotion', 'sales']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week_number</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>transferred</th>\n",
       "      <th>hol_type_Additional</th>\n",
       "      <th>hol_type_Bridge</th>\n",
       "      <th>hol_type_Event</th>\n",
       "      <th>hol_type_Holiday</th>\n",
       "      <th>hol_type_Transfer</th>\n",
       "      <th>hol_type_Work Day</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1282946</th>\n",
       "      <td>2015-04-11</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>C</td>\n",
       "      <td>15</td>\n",
       "      <td>Latacunga</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>2</td>\n",
       "      <td>407.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640467</th>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>Cuenca</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>0</td>\n",
       "      <td>695.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593946</th>\n",
       "      <td>2014-01-25</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>Quito</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>0</td>\n",
       "      <td>5452.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633785</th>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>A</td>\n",
       "      <td>14</td>\n",
       "      <td>Ambato</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>LIQUOR,WINE,BEER</td>\n",
       "      <td>2</td>\n",
       "      <td>88.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483934</th>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>C</td>\n",
       "      <td>15</td>\n",
       "      <td>Quito</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>MEATS</td>\n",
       "      <td>18</td>\n",
       "      <td>220.933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  year  month  week_number  day  day_of_week  store_nbr  \\\n",
       "1282946 2015-04-11  2015      4           15   11            5         13   \n",
       "2640467 2017-06-12  2017      6           24   12            0         37   \n",
       "593946  2014-01-25  2014      1            4   25            5          9   \n",
       "2633785 2017-06-08  2017      6           23    8            3         50   \n",
       "2483934 2017-03-16  2017      3           11   16            3         10   \n",
       "\n",
       "        type  cluster       city  ... transferred  hol_type_Additional  \\\n",
       "1282946    C       15  Latacunga  ...        None                False   \n",
       "2640467    D        2     Cuenca  ...        None                False   \n",
       "593946     B        6      Quito  ...        None                False   \n",
       "2633785    A       14     Ambato  ...        None                False   \n",
       "2483934    C       15      Quito  ...        None                False   \n",
       "\n",
       "         hol_type_Bridge  hol_type_Event hol_type_Holiday  hol_type_Transfer  \\\n",
       "1282946            False           False            False              False   \n",
       "2640467            False           False            False              False   \n",
       "593946             False           False            False              False   \n",
       "2633785            False           False            False              False   \n",
       "2483934            False           False            False              False   \n",
       "\n",
       "        hol_type_Work Day            family onpromotion     sales  \n",
       "1282946             False      BREAD/BAKERY           2   407.000  \n",
       "2640467             False      BREAD/BAKERY           0   695.903  \n",
       "593946              False         GROCERY I           0  5452.000  \n",
       "2633785             False  LIQUOR,WINE,BEER           2    88.000  \n",
       "2483934             False             MEATS          18   220.933  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week_number</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>transferred</th>\n",
       "      <th>hol_type_Additional</th>\n",
       "      <th>hol_type_Bridge</th>\n",
       "      <th>hol_type_Event</th>\n",
       "      <th>hol_type_Holiday</th>\n",
       "      <th>hol_type_Transfer</th>\n",
       "      <th>hol_type_Work Day</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1532213</th>\n",
       "      <td>2015-05-12</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>MAGAZINES</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282036</th>\n",
       "      <td>2013-06-08</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>Puyo</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>HOME CARE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994137</th>\n",
       "      <td>2017-08-12</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Quito</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>HARDWARE</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572044</th>\n",
       "      <td>2013-11-18</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Quito</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>LIQUOR,WINE,BEER</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573547</th>\n",
       "      <td>2013-11-18</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>A</td>\n",
       "      <td>17</td>\n",
       "      <td>Guayaquil</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>0</td>\n",
       "      <td>1283.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  year  month  week_number  day  day_of_week  store_nbr  \\\n",
       "1532213 2015-05-12  2015      5           20   12            1          5   \n",
       "282036  2013-06-08  2013      6           23    8            5         22   \n",
       "2994137 2017-08-12  2017      8           32   12            5          2   \n",
       "572044  2013-11-18  2013     11           47   18            0          1   \n",
       "573547  2013-11-18  2013     11           47   18            0         51   \n",
       "\n",
       "        type  cluster           city  ... transferred  hol_type_Additional  \\\n",
       "1532213    D        4  Santo Domingo  ...        None                False   \n",
       "282036     C        7           Puyo  ...        None                False   \n",
       "2994137    D       13          Quito  ...        None                False   \n",
       "572044     D       13          Quito  ...        None                False   \n",
       "573547     A       17      Guayaquil  ...        None                False   \n",
       "\n",
       "         hol_type_Bridge  hol_type_Event hol_type_Holiday  hol_type_Transfer  \\\n",
       "1532213            False           False            False              False   \n",
       "282036             False           False            False              False   \n",
       "2994137            False           False            False              False   \n",
       "572044             False           False            False              False   \n",
       "573547             False           False            False              False   \n",
       "\n",
       "        hol_type_Work Day            family onpromotion   sales  \n",
       "1532213             False         MAGAZINES           0     3.0  \n",
       "282036              False         HOME CARE           0     0.0  \n",
       "2994137             False          HARDWARE           0     1.0  \n",
       "572044              False  LIQUOR,WINE,BEER           0    77.0  \n",
       "573547              False          CLEANING           0  1283.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_alt.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.to_csv(\"../data/merged_train.csv\", index = False)\n",
    "#X_alt.to_csv(\"../data/merged_train_alt.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245784\n"
     ]
    }
   ],
   "source": [
    "print(X_alt['transactions'].isnull().sum())\n",
    "    # X_alt has missing values in transactions, and in the three holiday name columns\n",
    "    # the holiday day columns correspond to days with no holidays at all\n",
    "    # note that:\n",
    "        # number of fewer rows in merged_train == 245, 784 == number of missing transaction values in merged_train_alt \n",
    "    # i.e. merged_train has fewer rows, but has all values by skipping days without transaction data\n",
    "    # while merged_train_alt has all the original rows (3,000,888) but retains the NaN transaction values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
