{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "stores = pd.read_csv('../data/stores.csv')\n",
    "transactions = pd.read_csv('../data/transactions.csv')\n",
    "oil = pd.read_csv('../data/oil.csv')\n",
    "holidays = pd.read_csv('../data/holidays_events.csv')\n",
    "\n",
    "# Dictionary for all datasets\n",
    "datasets = {'train':train, 'test':test, 'stores':stores, 'transactions':transactions, 'oil':oil, 'holidays':holidays}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarizing dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert any dates in the datasets to pandas Timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in iter(datasets.values()):\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime( df['date'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Testing Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the `id` column from the training/testing set. The preliminary analysis proved this is just a redundant row indexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('id',axis=1)\n",
    "test = test.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oil Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change `dcoilwtico` to just `oil` for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil = oil.rename({'dcoilwtico': 'oil'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preliminary analysis shows 43 missing daily oil price values and missing weekend oil price values. \n",
    "\n",
    "We add the weekend days first as more null values, then interpolate \n",
    "\n",
    "Also, the oil price for the very first day (2013-01-01) is missing. We can manually add that here using the oil prices from 2012-12-31 and 2013-01-02 from (https://fred.stlouisfed.org/data/DCOILWTICO). We separately verified that is safe to do, since these oil prices match the ones in the oil dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually add oil price for the first day using average of 2012-12-31 and 2013-01-02 oil prices\n",
    "oil.iloc[0,1] = 92.485                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with all dates in desired range, including weekends\n",
    "dates = pd.DataFrame(pd.date_range(start='1/1/2013', end='8/31/2017',freq='D'), columns=['date'])\n",
    "# Merge with oil data set, so that weekend dates are added to oil with null values\n",
    "oil = dates.merge(oil,how='left', on='date')\n",
    "# Interpolate all missing values in oil (all but possibly one of the gaps are of size 1,2, or 3)\n",
    "oil['oil'] = oil['oil'].interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the `type` column so that it won't conflict with store type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = holidays.rename({'type':'hol_type'},axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the preliminary analysis, two transferred holidays need their description updated so that all tranfer holidays have consistent formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays.loc[304,'description'] = 'Traslado Fundacion de Cuenca'\n",
    "holidays.loc[329, 'description'] = 'Traslado Fundacion de Ibarra'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were also a couple mislabelled Additional Holidays, and one that should be deleted for redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays.loc[182,'type'] = 'Additional'\n",
    "holidays.loc[322,'type'] = 'Holiday'\n",
    "holidays = holidays.drop(264, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate the holiday `locale` variable into three columns (local, regional, national)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = pd.get_dummies(holidays, columns=['locale'],prefix='Hol')\n",
    "#We can adjust weights here or later\n",
    "holidays['Hol_Local']=holidays['Hol_Local']*1\n",
    "holidays['Hol_National']=holidays['Hol_National']*1\n",
    "holidays['Hol_Regional']=holidays['Hol_Regional']*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hol_type</th>\n",
       "      <th>city</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "      <th>Hol_Local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2015-11-12</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Ambato</td>\n",
       "      <td>Independencia de Ambato</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date hol_type    city              description  transferred  \\\n",
       "197 2015-11-12  Holiday  Ambato  Independencia de Ambato        False   \n",
       "\n",
       "     Hol_Local  \n",
       "197          1  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at local holidays\n",
    "hol_loc=holidays[holidays['Hol_Local']==1]\n",
    "hol_loc=hol_loc.rename(columns={'locale_name':'city'})\n",
    "hol_loc=hol_loc[['date', 'hol_type', 'city', 'description', 'transferred','Hol_Local']]\n",
    "hol_loc.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hol_type</th>\n",
       "      <th>state</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "      <th>Hol_Regional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2016-11-07</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Santa Elena</td>\n",
       "      <td>Provincializacion Santa Elena</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date hol_type        state                    description  \\\n",
       "279 2016-11-07  Holiday  Santa Elena  Provincializacion Santa Elena   \n",
       "\n",
       "     transferred  Hol_Regional  \n",
       "279        False             1  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at Regional holidays\n",
    "hol_reg=holidays[holidays['Hol_Regional']==1]\n",
    "hol_reg=hol_reg.rename(columns={'locale_name':'state'})\n",
    "hol_reg=hol_reg[['date', 'hol_type', 'state', 'description', 'transferred', 'Hol_Regional']]\n",
    "hol_reg.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hol_type</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "      <th>Hol_National</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2014-12-26</td>\n",
       "      <td>Additional</td>\n",
       "      <td>Navidad+1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date    hol_type description  transferred  Hol_National\n",
       "157 2014-12-26  Additional   Navidad+1        False             1"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at National holidays\n",
    "hol_nat=holidays[holidays['Hol_National']==1]\n",
    "hol_nat=hol_nat[['date', 'hol_type', 'description', 'transferred', 'Hol_National']]\n",
    "hol_nat.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map of national holidays\n",
    "holiday_nat_map = dict(zip(hol_nat['date'], hol_nat['Hol_National']))\n",
    "holiday_nat_type_map = dict(zip(hol_nat['date'], hol_nat['hol_type']))\n",
    "holiday_nat_name_map = dict(zip(hol_nat['date'], hol_nat['description']))\n",
    "holiday_nat_transf_map = dict(zip(hol_nat['date'], hol_nat['transferred']))\n",
    "\n",
    "# Create a map of regional holidays\n",
    "holiday_reg_map = dict(zip(zip(hol_reg['date'], hol_reg['state'].str.strip()), hol_reg['Hol_Regional']))\n",
    "holiday_reg_type_map = dict(zip(zip(hol_reg['date'], hol_reg['state'].str.strip()), hol_reg['hol_type']))\n",
    "holiday_reg_name_map = dict(zip(zip(hol_reg['date'], hol_reg['state'].str.strip()), hol_reg['description']))\n",
    "holiday_reg_transf_map = dict(zip(hol_reg['date'], hol_reg['transferred']))\n",
    "\n",
    "# Create a map of local holidays\n",
    "holiday_loc_map = dict(zip(zip(hol_loc['date'], hol_loc['city'].str.strip()), hol_loc['Hol_Local']))\n",
    "holiday_loc_type_map = dict(zip(zip(hol_loc['date'], hol_loc['city'].str.strip()), hol_loc['hol_type']))\n",
    "holiday_loc_name_map = dict(zip(zip(hol_loc['date'], hol_loc['city'].str.strip()), hol_loc['description']))\n",
    "holiday_loc_transf_map = dict(zip(zip(hol_loc['date'], hol_loc['city'].str.strip()), hol_loc['transferred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first inner join the store and transaction data along the `store_nbr` column.\n",
    "\n",
    "This guarantees no duplicates or new null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge stores with transactions on date and store_nbr\n",
    "X = stores.merge(transactions, how='inner', on='store_nbr')\n",
    "X = X.sort_values(by=['date','store_nbr'],axis=0).reset_index(drop=True)\n",
    "X = X[['date','store_nbr','type','cluster','city','state','transactions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before merging more data, we break down the `date` column into year, month, w|eek, day, and day of week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.assign(**{'year': pd.Series( [X.date[i].year for i in X.index]), \n",
    "            'month': pd.Series( [X.date[i].month for i in X.index]), \n",
    "            'week_number': pd.Series( [X.date[i].week for i in X.index]), \n",
    "            'day':pd.Series( [X.date[i].day for i in X.index]), \n",
    "            'day_of_week': pd.Series( [X.date[i].dayofweek for i in X.index]) })\n",
    "X = X[['date','year', 'month', 'week_number', 'day', 'day_of_week','store_nbr','type','cluster','city', 'state', 'transactions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we  join oil prices along the `date` column.\n",
    "\n",
    "Since there is one oil price per date and we filled null values in oil, this won't give duplicates or new null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.merge(oil, how='left', on='date')\n",
    "X = X.sort_values(by=['date','store_nbr'],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we inner join our training data along both `date` and `store_nbr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.merge(train, how='left', on=['date','store_nbr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we join the holiday data using the mappings defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/840b8l353yv58xh3z45hs1tc0000gn/T/ipykernel_43727/418294253.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[False False False ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X.loc[X['transferred'].isna(), 'transferred'] = X.loc[X['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
      "/var/folders/26/840b8l353yv58xh3z45hs1tc0000gn/T/ipykernel_43727/418294253.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Holiday' 'Holiday' 'Holiday' ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X.loc[X['hol_type'].isna(), 'hol_type'] = X['date'].map(holiday_nat_type_map)\n"
     ]
    }
   ],
   "source": [
    "# Add empty tranferred and holiday type columns\n",
    "X['transferred'] = np.nan\n",
    "X['hol_type'] = np.nan\n",
    "\n",
    "#Use mappings to fill in the values for national holidays\n",
    "X['hol_Nat'] = X['date'].map(holiday_nat_map)\n",
    "X.loc[X['transferred'].isna(), 'transferred'] = X.loc[X['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "X['hol_Nat_name'] = X['date'].map(holiday_nat_name_map)\n",
    "X.loc[X['hol_type'].isna(), 'hol_type'] = X['date'].map(holiday_nat_type_map)\n",
    "\n",
    "# Assign regional holidays based on mapping \n",
    "X['hol_Reg'] = X.apply(lambda row: holiday_reg_map.get((row['date'], row['state'])), axis=1)\n",
    "X.loc[X['transferred'].isna(), 'transferred'] = X.loc[X['transferred'].isna(), 'date'].map(holiday_reg_transf_map)\n",
    "X['hol_Reg_name'] = X.apply(lambda row: holiday_reg_name_map.get((row['date'], row['state'])), axis=1)\n",
    "X.loc[X['hol_type'].isna(), 'hol_type'] = X.loc[X['hol_type'].isna()].apply(lambda row: holiday_reg_type_map.get((row['date'], row['state'])), axis=1)\n",
    "\n",
    "# Assign local holidays based on mapping \n",
    "X['hol_Loc'] = X.apply(lambda row: holiday_loc_map.get((row['date'], row['city'])), axis=1)\n",
    "X.loc[X['transferred'].isna(), 'transferred'] = X.loc[X['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "\n",
    "X['transferred'] = X.apply(\n",
    "    lambda row: holiday_loc_map.get((row['date'], row['city'])) if pd.isna(row['transferred']) else row['transferred'], axis=1\n",
    ")\n",
    "X.loc[X['hol_type'].isna(), 'hol_type']= X.loc[X['hol_type'].isna()].apply(lambda row: holiday_loc_type_map.get((row['date'], row['city'])), axis=1)\n",
    "X['hol_loc_name'] = X.apply(lambda row: holiday_loc_name_map.get((row['date'], row['city'])), axis=1)\n",
    "\n",
    "# Just fillna\n",
    "X[['hol_Nat','hol_Reg','hol_Loc']]=X[['hol_Nat','hol_Reg','hol_Loc']].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder columns and create boolean columns for each holiday type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating types of the holidays \n",
    "X = pd.get_dummies(X,columns=['hol_type'], prefix='hol_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorder columns\n",
    "X = X[['date', 'year', 'month', 'week_number', 'day', 'day_of_week',\n",
    "       'store_nbr', 'type', 'cluster', 'city', 'state', 'transactions', 'oil',\n",
    "       'hol_Nat', 'hol_Nat_name', 'hol_Reg', 'hol_Reg_name', 'hol_Loc','hol_loc_name', \n",
    "       'transferred','hol_type_Additional', 'hol_type_Bridge', 'hol_type_Event',\n",
    "       'hol_type_Holiday', 'hol_type_Transfer', 'hol_type_Work Day',\n",
    "       'family', 'onpromotion', 'sales']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging (Alternative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach to merging starts with the training set, and ensures no rows of the training data are lost. However, as a result of NaN values and missing dates among the other data sets, this might contain some NaN values.\n",
    "\n",
    "Start with DataFrames containing all dates in the desired time frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame with all the days\n",
    "train_dates = pd.DataFrame(pd.date_range(start='1/1/2013', end='8/15/2017',freq='D'), columns=['date'])\n",
    "test_dates = pd.DataFrame(pd.date_range(start='8/16/2017', end='8/31/2017',freq='D'), columns=['date'])\n",
    "\n",
    "# Breaking down dates into year, month, day, etc.\n",
    "train_dates = train_dates.assign(**{'year': pd.Series( [train_dates.date[i].year for i in train_dates.index]), \n",
    "            'month': pd.Series( [train_dates.date[i].month for i in train_dates.index]), \n",
    "            'week_number': pd.Series( [train_dates.date[i].week for i in train_dates.index]), \n",
    "            'day':pd.Series( [train_dates.date[i].day for i in train_dates.index]), \n",
    "            'day_of_week': pd.Series( [train_dates.date[i].dayofweek for i in train_dates.index]) })\n",
    "test_dates = test_dates.assign(**{'year': pd.Series( [test_dates.date[i].year for i in test_dates.index]), \n",
    "            'month': pd.Series( [test_dates.date[i].month for i in test_dates.index]), \n",
    "            'week_number': pd.Series( [test_dates.date[i].week for i in test_dates.index]), \n",
    "            'day':pd.Series( [test_dates.date[i].day for i in test_dates.index]), \n",
    "            'day_of_week': pd.Series( [test_dates.date[i].dayofweek for i in test_dates.index]) })\n",
    "\n",
    "# Reorder columns\n",
    "train_dates = train_dates[['date','year', 'month', 'week_number', 'day', 'day_of_week']]\n",
    "test_dates = test_dates[['date','year', 'month', 'week_number', 'day', 'day_of_week']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add oil price for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add oil price for each day\n",
    "X_alt = oil.merge(train_dates, how='inner', on='date')\n",
    "y_alt = oil.merge(test_dates, how='inner', on='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left join training set data (left) with date/oil (right) along the `date` column.\n",
    "\n",
    "This ensures all training data is kept, while the date DataFrame drops December 25 2013, 2014, 2015, 2016, which are missing from train.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_alt = train.merge(X_alt, how='left', on='date')           # 3,000,888 rows\n",
    "y_alt = test.merge(y_alt, how='left', on='date')            # 28,512 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left join merged data (left) with stores (right) along the `store_nbr` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_alt = X_alt.merge(stores, how='left', on='store_nbr')     # 3,000,888 rows\n",
    "y_alt = y_alt.merge(stores, how='left', on='store_nbr')     # 28,512 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left join merged date (left) with transactions along `date` then `store_nbr`.\n",
    "\n",
    "Transactions is additionally missing data for Jan 1 and Jan 3 of 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the testing set has no transaction data, so we can't add that here\n",
    "X_alt = X_alt.merge(transactions, how='left', on=['date','store_nbr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we add the holiday data using the mappings we constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/840b8l353yv58xh3z45hs1tc0000gn/T/ipykernel_43727/3630162675.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[False False False ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X_alt.loc[X_alt['transferred'].isna(), 'transferred'] = X_alt.loc[X_alt['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
      "/var/folders/26/840b8l353yv58xh3z45hs1tc0000gn/T/ipykernel_43727/3630162675.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Holiday' 'Holiday' 'Holiday' ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X_alt.loc[X_alt['hol_type'].isna(), 'hol_type'] = X_alt['date'].map(holiday_nat_type_map)\n"
     ]
    }
   ],
   "source": [
    "# Add empty transferred and holiday type columns\n",
    "X_alt['transferred'] = np.nan\n",
    "X_alt['hol_type'] = np.nan\n",
    "\n",
    "#Use mappings to fill in the values for national holidays\n",
    "X_alt['hol_Nat'] = X_alt['date'].map(holiday_nat_map)\n",
    "X_alt.loc[X_alt['transferred'].isna(), 'transferred'] = X_alt.loc[X_alt['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "X_alt['hol_Nat_name'] = X_alt['date'].map(holiday_nat_name_map)\n",
    "X_alt.loc[X_alt['hol_type'].isna(), 'hol_type'] = X_alt['date'].map(holiday_nat_type_map)\n",
    "\n",
    "# Assign regional holidays based on mapping \n",
    "X_alt['hol_Reg'] = X_alt.apply(lambda row: holiday_reg_map.get((row['date'], row['state'])), axis=1)\n",
    "X_alt.loc[X_alt['transferred'].isna(), 'transferred'] = X_alt.loc[X_alt['transferred'].isna(), 'date'].map(holiday_reg_transf_map)\n",
    "X_alt['hol_Reg_name'] = X_alt.apply(lambda row: holiday_reg_name_map.get((row['date'], row['state'])), axis=1)\n",
    "X_alt.loc[X_alt['hol_type'].isna(), 'hol_type'] = X_alt.loc[X_alt['hol_type'].isna()].apply(lambda row: holiday_reg_type_map.get((row['date'], row['state'])), axis=1)\n",
    "\n",
    "# Assign local holidays based on mapping \n",
    "X_alt['hol_Loc'] = X_alt.apply(lambda row: holiday_loc_map.get((row['date'], row['city'])), axis=1)\n",
    "X_alt.loc[X_alt['transferred'].isna(), 'transferred'] = X_alt.loc[X_alt['transferred'].isna(), 'date'].map(holiday_nat_transf_map)\n",
    "\n",
    "X_alt['transferred'] = X_alt.apply(\n",
    "    lambda row: holiday_loc_map.get((row['date'], row['city'])) if pd.isna(row['transferred']) else row['transferred'], axis=1\n",
    ")\n",
    "X_alt.loc[X_alt['hol_type'].isna(), 'hol_type']= X_alt.loc[X_alt['hol_type'].isna()].apply(lambda row: holiday_loc_type_map.get((row['date'], row['city'])), axis=1)\n",
    "X_alt['hol_loc_name'] = X_alt.apply(lambda row: holiday_loc_name_map.get((row['date'], row['city'])), axis=1)\n",
    "\n",
    "# Just fillna\n",
    "X_alt[['hol_Nat','hol_Reg','hol_Loc']]=X_alt[['hol_Nat','hol_Reg','hol_Loc']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating types of the holidays \n",
    "X_alt = pd.get_dummies(X_alt,columns=['hol_type'], prefix='hol_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "X_alt = X_alt[['date', 'year', 'month', 'week_number', 'day', 'day_of_week', \n",
    "       'store_nbr','type', 'cluster', 'city', 'state','transactions','oil',\n",
    "       'hol_Nat','hol_Nat_name',  'hol_Reg','hol_Reg_name','hol_Loc','hol_loc_name',\n",
    "       'transferred','hol_type_Additional','hol_type_Bridge', 'hol_type_Event',\n",
    "       'hol_type_Holiday', 'hol_type_Transfer', 'hol_type_Work Day',\n",
    "       'family', 'onpromotion', 'sales']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week_number</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>transferred</th>\n",
       "      <th>hol_type_Additional</th>\n",
       "      <th>hol_type_Bridge</th>\n",
       "      <th>hol_type_Event</th>\n",
       "      <th>hol_type_Holiday</th>\n",
       "      <th>hol_type_Transfer</th>\n",
       "      <th>hol_type_Work Day</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1282946</th>\n",
       "      <td>2015-04-11</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>C</td>\n",
       "      <td>15</td>\n",
       "      <td>Latacunga</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>2</td>\n",
       "      <td>407.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640467</th>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>Cuenca</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>0</td>\n",
       "      <td>695.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593946</th>\n",
       "      <td>2014-01-25</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>Quito</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>0</td>\n",
       "      <td>5452.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633785</th>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>A</td>\n",
       "      <td>14</td>\n",
       "      <td>Ambato</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>LIQUOR,WINE,BEER</td>\n",
       "      <td>2</td>\n",
       "      <td>88.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483934</th>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>C</td>\n",
       "      <td>15</td>\n",
       "      <td>Quito</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>MEATS</td>\n",
       "      <td>18</td>\n",
       "      <td>220.933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  year  month  week_number  day  day_of_week  store_nbr  \\\n",
       "1282946 2015-04-11  2015      4           15   11            5         13   \n",
       "2640467 2017-06-12  2017      6           24   12            0         37   \n",
       "593946  2014-01-25  2014      1            4   25            5          9   \n",
       "2633785 2017-06-08  2017      6           23    8            3         50   \n",
       "2483934 2017-03-16  2017      3           11   16            3         10   \n",
       "\n",
       "        type  cluster       city  ... transferred  hol_type_Additional  \\\n",
       "1282946    C       15  Latacunga  ...        None                False   \n",
       "2640467    D        2     Cuenca  ...        None                False   \n",
       "593946     B        6      Quito  ...        None                False   \n",
       "2633785    A       14     Ambato  ...        None                False   \n",
       "2483934    C       15      Quito  ...        None                False   \n",
       "\n",
       "         hol_type_Bridge  hol_type_Event hol_type_Holiday  hol_type_Transfer  \\\n",
       "1282946            False           False            False              False   \n",
       "2640467            False           False            False              False   \n",
       "593946             False           False            False              False   \n",
       "2633785            False           False            False              False   \n",
       "2483934            False           False            False              False   \n",
       "\n",
       "        hol_type_Work Day            family onpromotion     sales  \n",
       "1282946             False      BREAD/BAKERY           2   407.000  \n",
       "2640467             False      BREAD/BAKERY           0   695.903  \n",
       "593946              False         GROCERY I           0  5452.000  \n",
       "2633785             False  LIQUOR,WINE,BEER           2    88.000  \n",
       "2483934             False             MEATS          18   220.933  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week_number</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>transferred</th>\n",
       "      <th>hol_type_Additional</th>\n",
       "      <th>hol_type_Bridge</th>\n",
       "      <th>hol_type_Event</th>\n",
       "      <th>hol_type_Holiday</th>\n",
       "      <th>hol_type_Transfer</th>\n",
       "      <th>hol_type_Work Day</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1042997</th>\n",
       "      <td>2014-08-10</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "      <td>Ambato</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>0</td>\n",
       "      <td>15.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475810</th>\n",
       "      <td>2013-09-25</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Quito</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>HOME AND KITCHEN II</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182063</th>\n",
       "      <td>2014-10-27</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>D</td>\n",
       "      <td>10</td>\n",
       "      <td>Guayaquil</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>1</td>\n",
       "      <td>818.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299378</th>\n",
       "      <td>2013-06-18</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Quito</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317853</th>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>Playas</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SCHOOL AND OFFICE SUPPLIES</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  year  month  week_number  day  day_of_week  store_nbr  \\\n",
       "1042997 2014-08-10  2014      8           32   10            6         23   \n",
       "475810  2013-09-25  2013      9           39   25            2          1   \n",
       "1182063 2014-10-27  2014     10           44   27            0         26   \n",
       "299378  2013-06-18  2013      6           25   18            1          1   \n",
       "1317853 2015-01-12  2015      1            3   12            0         35   \n",
       "\n",
       "        type  cluster       city  ... transferred  hol_type_Additional  \\\n",
       "1042997    D        9     Ambato  ...       False                False   \n",
       "475810     D       13      Quito  ...        None                False   \n",
       "1182063    D       10  Guayaquil  ...        None                False   \n",
       "299378     D       13      Quito  ...        None                False   \n",
       "1317853    C        3     Playas  ...        None                False   \n",
       "\n",
       "         hol_type_Bridge  hol_type_Event hol_type_Holiday  hol_type_Transfer  \\\n",
       "1042997            False           False             True              False   \n",
       "475810             False           False            False              False   \n",
       "1182063            False           False            False              False   \n",
       "299378             False           False            False              False   \n",
       "1317853            False           False            False              False   \n",
       "\n",
       "        hol_type_Work Day                      family onpromotion    sales  \n",
       "1042997             False                     SEAFOOD           0   15.778  \n",
       "475810              False         HOME AND KITCHEN II           0    0.000  \n",
       "1182063             False                   BEVERAGES           1  818.000  \n",
       "299378              False                      BEAUTY           0    4.000  \n",
       "1317853             False  SCHOOL AND OFFICE SUPPLIES           0    0.000  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_alt.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"../data/merged_train.csv\", index = False)\n",
    "X_alt.to_csv(\"../data/merged_train_alt.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
